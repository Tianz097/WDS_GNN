{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fd60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff3b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import numpy as np \n",
    "import random\n",
    "import tqdm\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter \n",
    "import networkx as nx\n",
    "import copy\n",
    "import pandas as pd\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c06def",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to get all removable links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41cd0a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removable_links(inp_file):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "    removable_links = []\n",
    "    G = wn.to_graph(wn)\n",
    "    # Store not-deadend pipes to be removed\n",
    "    for _, link in wn.links():\n",
    "        if (link.link_type == 'Pipe' and\n",
    "            link.start_node.node_type == 'Junction' and\n",
    "            link.end_node.node_type == 'Junction' and\n",
    "            G.degree[link.start_node.name] > 1 and\n",
    "            G.degree[link.end_node.name] > 1):\n",
    "            removable_links.append(link)\n",
    "\n",
    "\n",
    "    return removable_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3b79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removable_pairs(removable_links,limited_combinations):\n",
    "    removable_pairs = []\n",
    "    \n",
    "    for (link1, link2) in limited_combinations:\n",
    "\n",
    "        wnr = copy.deepcopy(wn)\n",
    "        wnr.remove_link(link1)\n",
    "        wnr.remove_link(link2)\n",
    "        Gr = wnr.to_graph().to_undirected()\n",
    "        if nx.is_connected(Gr):\n",
    "            removable_pairs.append((link1, link2))\n",
    "                \n",
    "    return removable_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca2d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd469c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'bwflnet_no_control'\n",
    "inp_file = network + '.inp'\n",
    "wn = wntr.network.WaterNetworkModel(inp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7525569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the removable links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81e8e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get removable links\n",
    "removable_links = get_removable_links(inp_file)\n",
    "\n",
    "num_nodes = wn.num_nodes\n",
    "num_links = wn.num_links\n",
    "num_time = 5\n",
    "n_sims = 3\n",
    "#num_time = int(wn.options.time.duration / wn.options.time.report_timestep + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b6630",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_combinations = 500\n",
    "limited_combinations = itertools.islice(itertools.combinations(removable_links, 2), n_combinations)\n",
    "removable_pairs = get_removable_pairs(removable_links,limited_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((n_sims , num_links*num_time, 3))\n",
    "B = np.zeros((n_sims , num_nodes*num_time, 6))\n",
    "U = np.zeros((n_sims , num_nodes*num_time, 1))\n",
    "# Store the randomly chosen pairs of removable links\n",
    "links2remove = random.sample(removable_pairs, n_sims)\n",
    "\n",
    "## Measurement when fully-supervised\n",
    "measurement_fully = []\n",
    "monitor = ['5', '11', '32', '37', '44']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49254869",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in range(n_sims):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)  # reset value\n",
    "    wn.options.hydraulic.demand_model = 'DD' #dynamic demand model\n",
    "\n",
    "    i = 0\n",
    "    for _, node in wn.nodes():\n",
    "        node.id = i\n",
    "        i += 1\n",
    "\n",
    "    if sim != 0:\n",
    "        (link1, link2) = links2remove[sim - 1]\n",
    "        wn.remove_link(link1)\n",
    "        wn.remove_link(link2)\n",
    "\n",
    "    i = 0\n",
    "    for _, link in wn.links():\n",
    "        A[sim, i, 0] = link.start_node.id\n",
    "        A[sim, i, 1] = link.end_node.id\n",
    "        if link.link_type == \"pipes\":\n",
    "            A[sim, i, 2] = 1 / (10.667 *link.length / link.roughness ** 1.852 /link.diameter ** 4.871)\n",
    "        else:\n",
    "            A[sim, i, 2] = 0\n",
    "        i += 1\n",
    "\n",
    "    results = wntr.sim.EpanetSimulator(wn).run_sim(version=2.0)\n",
    "    head = results.node['head']\n",
    "    demand = results.node['demand']\n",
    "    demand = np.maximum(demand, 0)\n",
    "    \n",
    "    ### Produce datas for multiple timestep\n",
    "    #### Time step\n",
    "    index_values = head.index.values\n",
    "    np.random.seed(42)\n",
    "    Time_step = np.random.choice(index_values, size=num_time, replace=False)\n",
    "    \n",
    "    repeated_timestep = pd.Series(Time_step).repeat(num_nodes).reset_index(drop=True)\n",
    "    Time_indicator = pd.DataFrame({'Timestep': repeated_timestep})\n",
    "    Time_indicator = Time_indicator.squeeze()\n",
    "    \n",
    "    #### Demand\n",
    "    demand_s = demand.loc[Time_step]\n",
    "    demand_s = demand_s.values.flatten()\n",
    "    #### Head\n",
    "    head_s = head.loc[Time_step]\n",
    "    head_s = head_s.values.flatten()\n",
    "    #### Node indicator (the number of the node)\n",
    "    Node_indicator = np.tile(np.arange(1, num_nodes+1), num_time)\n",
    "        # Measurement when fully-supervised\n",
    "    measurement_fully = Node_indicator\n",
    "    #### Junction indicator (if the node is not a reservoir, junction indicator = 1)\n",
    "    Nd_single = np.array([1 if node.node_type == 'Junction' else 0 for _, node in wn.nodes()])\n",
    "    Nd = np.tile(Nd_single,num_time)\n",
    "    Nd = Nd.squeeze()\n",
    "    #### Measurement indicator (if the node has head, measurement indicator = 1) (fully-supervised, all 1)\n",
    "    Nh_single = np.zeros(num_nodes)\n",
    "    Nh = np.tile(Nh_single,num_time)\n",
    "    Nh = Nh.squeeze()\n",
    "    ###\n",
    "    \n",
    "    ### Node\n",
    "    B[sim, :, 0] = Time_indicator\n",
    "    B[sim, :, 1] = Node_indicator\n",
    "    B[sim, :, 2] = Nd\n",
    "    B[sim, :, 3] = demand_s\n",
    "    B[sim, :, 4] = Nh\n",
    "    B[sim, :, 5] = (1 - Nh) * head_s\n",
    "    ###\n",
    "\n",
    "    U[sim, :, 0] = head_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d90887",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edge\n",
    "A_re = A[:, :num_links, :]  # Extract the first 65 rows along the second axis\n",
    "\n",
    "# Repeat the 65 rows to cover the entire second axis\n",
    "A_re = np.tile(A_re, (1, num_links, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_3d_shape = B.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "B_2d = B.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "node_df = pd.DataFrame(B_2d)\n",
    "\n",
    "array_3d_shape = A_re.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "A_2d = A_re.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "edge_df = pd.DataFrame(A_2d)\n",
    "\n",
    "array_3d_shape = U.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "U_2d = U.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "graph_df = pd.DataFrame(U_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8589e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df.rename(columns={0: 'head'},inplace=True)\n",
    "edge_df.rename(columns={0: 'source', 1: 'target', 2: 'loss_co'},inplace=True)\n",
    "node_df.rename(columns={0:'Time_indicator', 1: 'Node_indicator', 2:'Junction_in',3: 'demand', 4: 'Measurement_in',5:'measurement'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge\n",
    "## Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Select the column to scale\n",
    "column_to_scale = 'loss_co'\n",
    "\n",
    "## Fit and transform the selected column\n",
    "edge_df[column_to_scale] = scaler.fit_transform(edge_df[[column_to_scale]])\n",
    "#\n",
    "# Node\n",
    "## Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Select the column to scale\n",
    "columns_to_scale = ['demand', 'measurement']\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "node_df[columns_to_scale] = scaler.fit_transform(node_df[columns_to_scale])\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edge_df = edge_df[n_sims * num_links * (num_time - 1):]\n",
    "test_node_df = node_df[n_sims * num_nodes * (num_time - 1):]\n",
    "\n",
    "train_edge_df = edge_df[:n_sims * num_links * (num_time - 1)]\n",
    "train_node_df = node_df[:n_sims * num_nodes * (num_time - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_tensor(node_df, edge_df):\n",
    "    graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "\n",
    "        node_sets={\n",
    "            \"node\": tfgnn.NodeSet.from_fields(\n",
    "                sizes=[len(node_df)],\n",
    "                features={\n",
    "                    #'Node_indicator':np.array(node_df['Node_indicator'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'Junction_in':np.array(node_df['Junction_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'demand': np.array(node_df['demand'], dtype='float32').reshape(len(node_df),1),\n",
    "                    'Measurement_in': np.array(node_df['Measurement_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'measurement': np.array(node_df['measurement'], dtype='float32').reshape(len(node_df),1),\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        edge_sets={\n",
    "            \"link\": tfgnn.EdgeSet.from_fields(\n",
    "                sizes=[len(edge_df)],\n",
    "                features={\n",
    "                    'loss_co': np.array(edge_df['loss_co'], dtype='float32').reshape(len(edge_df),1),\n",
    "                },\n",
    "                adjacency=tfgnn.Adjacency.from_indices(\n",
    "                                          source=(\"node\", np.array(edge_df['source'], dtype='int32')),\n",
    "                                          target=(\"node\", np.array(edge_df['target'], dtype='int32')),\n",
    "                                      ))\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return graph_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1bbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = create_graph_tensor(node_df, edge_df)\n",
    "train_tensor = create_graph_tensor(train_node_df, train_edge_df)\n",
    "test_tensor = create_graph_tensor(test_node_df, test_edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65049d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_batch_merge(graph):\n",
    "    graph = graph.merge_batch_to_components()\n",
    "    node_features = graph.node_sets['node'].get_features_dict()\n",
    "    edge_features = graph.edge_sets['link'].get_features_dict()\n",
    "    \n",
    "    label = node_features.pop('measurement')\n",
    "    print(label)\n",
    "    new_graph = graph.replace_features(node_sets={'node': node_features}, edge_sets={'link': edge_features})\n",
    "    \n",
    "    return new_graph, label\n",
    "\n",
    "\n",
    "     \n",
    "def create_dataset(graph, function):\n",
    "    dataset = tf.data.Dataset.from_tensors(graph)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset.map(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_node_dataset = create_dataset(full_tensor, node_batch_merge)\n",
    "train_node_dataset = create_dataset(train_tensor, node_batch_merge)\n",
    "test_node_dataset = create_dataset(test_tensor, node_batch_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_spec = train_node_dataset.element_spec[0]\n",
    "input_graph = tf.keras.layers.Input(type_spec=graph_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67604f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_node_state(node_set, node_set_name):\n",
    "    features = [\n",
    "        #tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Node_indicator']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Junction_in']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['demand']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Measurement_in']),\n",
    "        #tf.keras.layers.Dense(32, activation=\"relu\")(node_set['measurement']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n",
    "def set_initial_edge_state(edge_set, edge_set_name):\n",
    "    features = [\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(edge_set['loss_co']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n",
    "graph = tfgnn.keras.layers.MapFeatures(node_sets_fn=set_initial_node_state,\n",
    "                                       edge_sets_fn=set_initial_edge_state)(input_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c456585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(units=32, l2_reg=0.1, dropout=0.25, activation='relu'):\n",
    "    regularizer = tf.keras.regularizers.l2(l2_reg)\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, kernel_regularizer=regularizer, bias_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(dropout)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_updates = 5\n",
    "for i in range(graph_updates):\n",
    "    graph = tfgnn.keras.layers.GraphUpdate(\n",
    "        node_sets={\n",
    "            'node':\n",
    "            tfgnn.keras.layers.NodeSetUpdate(\n",
    "                {\n",
    "                    'link':\n",
    "                    tfgnn.keras.layers.SimpleConv(message_fn=dense_layer(16),\n",
    "                                                  reduce_type=\"mean\",\n",
    "                                                  sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
    "                                                  receiver_tag=tfgnn.TARGET)\n",
    "                }, tfgnn.keras.layers.NextStateFromConcat(dense_layer(32)))\n",
    "        })(graph)\n",
    "\n",
    "dense1 = tf.keras.layers.Dense(64)(graph.node_sets[\"node\"][tfgnn.HIDDEN_STATE])\n",
    "dense2 = tf.keras.layers.Dense(64)(dense1)\n",
    "dense3 = tf.keras.layers.Dense(1)(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c407cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_model = tf.keras.Model(input_graph, dense3)\n",
    "node_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                   loss='mean_squared_error',\n",
    "                   metrics=['Accuracy'])\n",
    "node_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                      mode='min',\n",
    "                                      verbose=1,\n",
    "                                      patience=10,\n",
    "                                      restore_best_weights=True)\n",
    "\n",
    "node_model.fit(train_node_dataset.repeat(),\n",
    "               validation_data=full_node_dataset,\n",
    "               steps_per_epoch=100,\n",
    "               epochs=100,\n",
    "               callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f6914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
