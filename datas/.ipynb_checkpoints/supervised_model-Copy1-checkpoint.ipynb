{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1fbc574",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0107e16",
   "metadata": {},
   "source": [
    "256√ó169 samples</p>\n",
    "### Change demand\n",
    "timestep = 1h, 1 week ->169 timesteps in total</p>\n",
    "at every timestep, change the nodal demand</p>\n",
    "### Change topology\n",
    "Randomly cut the connectivity between two pipes, but preserving the connectivity between each node in the network and source. ->256 topology\n",
    "\n",
    "### Try single timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9ca9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import numpy as np \n",
    "import random\n",
    "import tqdm\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter \n",
    "import networkx as nx\n",
    "import copy\n",
    "import pandas as pd\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80627a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removable_links(inp_file):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "    removable_links = []\n",
    "    G = wn.to_graph(wn)\n",
    "    # Store not-deadend pipes to be removed\n",
    "    for _, link in wn.links():\n",
    "        if (link.link_type == 'Pipe' and\n",
    "            link.start_node.node_type == 'Junction' and\n",
    "            link.end_node.node_type == 'Junction' and\n",
    "            G.degree[link.start_node.name] > 1 and\n",
    "            G.degree[link.end_node.name] > 1):\n",
    "            removable_links.append(link)\n",
    "    # To find pairs of links that can be removed together while keeping the network graph connected\n",
    "    removable_pairs = []\n",
    "    for (link1, link2) in itertools.combinations(removable_links, 2):\n",
    "        wnr = copy.deepcopy(wn)  #create a new reference to the same object\n",
    "        wnr.remove_link(link1)\n",
    "        wnr.remove_link(link2)\n",
    "        Gr = wnr.to_graph().to_undirected()\n",
    "        if nx.is_connected(Gr):\n",
    "            removable_pairs.append((link1, link2))\n",
    "\n",
    "    return removable_links, removable_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101893f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'ASnet2'\n",
    "inp_file = network + '.inp'\n",
    "wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "\n",
    "# get removable links\n",
    "removable_links, removable_pairs = get_removable_links(inp_file)\n",
    "num_nodes = wn.num_nodes\n",
    "num_links = wn.num_links\n",
    "num_time = 5\n",
    "#num_time = int(wn.options.time.duration / wn.options.time.report_timestep + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47c0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sims = 256\n",
    "#ùëâ_ùëñ=[ ùêº_ùëñ^ùëë, ùëû_ùëñ, ùêº_ùëñ^ùëö,ùêª_ùëñ^‚àó ] \n",
    "#ùê∏_ùëù=[ùëñ,ùëó,ùëê_ùëù]\n",
    "#Create data matrix\n",
    "A = np.zeros((n_sims , num_links*num_time, 3))\n",
    "B = np.zeros((n_sims , num_nodes*num_time, 6))\n",
    "\n",
    "\n",
    "#A = np.zeros((n_sims * num_time, num_links, 3))\n",
    "#B = np.zeros((n_sims * num_time, num_nodes, 4))\n",
    "#U = np.zeros((n_sims * num_time, num_nodes, 1))\n",
    "\n",
    "# Store the randomly chosen pairs of removable links\n",
    "links2remove = random.sample(removable_pairs, n_sims)\n",
    "\n",
    "## Measurement when fully-supervised\n",
    "measurement_fully = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d43e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in range(n_sims):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)  # reset value\n",
    "    wn.options.hydraulic.demand_model = 'DD' #dynamic demand model\n",
    "\n",
    "    i = 0\n",
    "    for _, node in wn.nodes():\n",
    "        node.id = i\n",
    "        i += 1\n",
    "\n",
    "    if sim != 0:\n",
    "        (link1, link2) = links2remove[sim - 1]\n",
    "        wn.remove_link(link1)\n",
    "        wn.remove_link(link2)\n",
    "\n",
    "    i = 0\n",
    "    for _, link in wn.links():\n",
    "        A[sim, i, 0] = link.start_node.id\n",
    "        A[sim, i, 1] = link.end_node.id\n",
    "        A[sim, i, 2] = 1 / (10.667 *link.length / link.roughness ** 1.852 /link.diameter ** 4.871)\n",
    "        i += 1\n",
    "\n",
    "    results = wntr.sim.EpanetSimulator(wn).run_sim(version=2.0)\n",
    "    head = results.node['head']\n",
    "    demand = results.node['demand']\n",
    "    demand = np.maximum(demand, 0)\n",
    "    \n",
    "    ### Produce datas for multiple timestep\n",
    "    #### Time step\n",
    "    index_values = head.index.values\n",
    "    np.random.seed(42)\n",
    "    Time_step = np.random.choice(index_values, size=5, replace=False)\n",
    "    \n",
    "    repeated_timestep = pd.Series(Time_step).repeat(num_nodes).reset_index(drop=True)\n",
    "    Time_indicator = pd.DataFrame({'Timestep': repeated_timestep})\n",
    "    Time_indicator = Time_indicator.squeeze()\n",
    "    \n",
    "    #### Demand\n",
    "    demand_s = demand.loc[Time_step]\n",
    "    demand_s = demand_s.values.flatten()\n",
    "    #### Head\n",
    "    head_s = head.loc[Time_step]\n",
    "    head_s = head_s.values.flatten()\n",
    "    #### Node indicator (the number of the node)\n",
    "    Node_indicator = np.tile(np.arange(1, num_nodes+1), num_time)\n",
    "        # Measurement when fully-supervised\n",
    "    measurement_fully = Node_indicator\n",
    "    #### Junction indicator (if the node is not a reservoir, junction indicator = 1)\n",
    "    Nd_single = np.array([1 if node.node_type == 'Junction' else 0 for _, node in wn.nodes()])\n",
    "    Nd = np.tile(Nd_single,num_time)\n",
    "    Nd = Nd.squeeze()\n",
    "    #### Measurement indicator (if the node has head, measurement indicator = 1) (fully-supervised, all 1)\n",
    "    Nh_single = np.zeros(num_nodes)\n",
    "    Nh = np.tile(Nh_single,num_time)\n",
    "    Nh = Nh.squeeze()\n",
    "    ###\n",
    "    \n",
    "    ### Node\n",
    "    B[sim, :, 0] = Time_indicator\n",
    "    B[sim, :, 1] = Node_indicator\n",
    "    B[sim, :, 2] = Nd\n",
    "    B[sim, :, 3] = demand_s\n",
    "    B[sim, :, 4] = Nh\n",
    "    B[sim, :, 5] = (1 - Nh) * head_s\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa712e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edge\n",
    "A_re = A[:, :65, :]  # Extract the first 65 rows along the second axis\n",
    "\n",
    "# Repeat the 65 rows to cover the entire second axis\n",
    "A_re = np.tile(A_re, (1, num_time, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c92515",
   "metadata": {},
   "source": [
    "### Change 3-d array to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c5ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_3d_shape = B.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "B_2d = B.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "node_df = pd.DataFrame(B_2d)\n",
    "\n",
    "array_3d_shape = A_re.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "A_2d = A_re.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "edge_df = pd.DataFrame(A_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff6cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df.rename(columns={0: 'source', 1: 'target', 2: 'loss_co'},inplace=True)\n",
    "node_df.rename(columns={0:'Time_indicator', 1: 'Node_indicator', 2:'Junction_in',3: 'demand', 4: 'Measurement_in',5:'measurement'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293e0425",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15b3f556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_indicator</th>\n",
       "      <th>Node_indicator</th>\n",
       "      <th>Junction_in</th>\n",
       "      <th>demand</th>\n",
       "      <th>Measurement_in</th>\n",
       "      <th>measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>496800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.410048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.044707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>496800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.581834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496800.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.881058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496800.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.244421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.040970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time_indicator  Node_indicator  Junction_in    demand  Measurement_in  \\\n",
       "0        496800.0             1.0          1.0 -0.410048             0.0   \n",
       "1        496800.0             2.0          1.0  0.155513             0.0   \n",
       "2        496800.0             3.0          1.0  1.581834             0.0   \n",
       "3        496800.0             4.0          1.0  2.881058             0.0   \n",
       "4        496800.0             5.0          1.0 -0.244421             0.0   \n",
       "\n",
       "   measurement  \n",
       "0    -0.044707  \n",
       "1    -0.046332  \n",
       "2    -0.045113  \n",
       "3    -0.025940  \n",
       "4    -0.040970  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge\n",
    "## Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Select the column to scale\n",
    "column_to_scale = 'loss_co'\n",
    "\n",
    "## Fit and transform the selected column\n",
    "edge_df[column_to_scale] = scaler.fit_transform(edge_df[[column_to_scale]])\n",
    "#\n",
    "# Node\n",
    "## Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Select the column to scale\n",
    "columns_to_scale = ['demand', 'measurement']\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "node_df[columns_to_scale] = scaler.fit_transform(node_df[columns_to_scale])\n",
    "#\n",
    "\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f714fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edge_df = edge_df[n_sims*num_links*(num_time-1):]\n",
    "test_node_df = node_df[n_sims*num_nodes*(num_time-1):]\n",
    "\n",
    "train_edge_df = edge_df[:n_sims*num_links*(num_time-1)]\n",
    "train_node_df = node_df[:n_sims*num_nodes*(num_time-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8448eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_tensor(node_df, edge_df):\n",
    "    graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "        node_sets={\n",
    "            \"node\": tfgnn.NodeSet.from_fields(\n",
    "                sizes=[len(node_df)],\n",
    "                features={\n",
    "                    #'Node_indicator':np.array(node_df['Node_indicator'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'Junction_in':np.array(node_df['Junction_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'demand': np.array(node_df['demand'], dtype='float32').reshape(len(node_df),1),\n",
    "                    'Measurement_in': np.array(node_df['Measurement_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'measurement': np.array(node_df['measurement'], dtype='float32').reshape(len(node_df),1),\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        edge_sets={\n",
    "            \"link\": tfgnn.EdgeSet.from_fields(\n",
    "                sizes=[len(edge_df)],\n",
    "                features={\n",
    "                    'loss_co': np.array(edge_df['loss_co'], dtype='float32').reshape(len(edge_df),1),\n",
    "                },\n",
    "                adjacency=tfgnn.Adjacency.from_indices(\n",
    "                                          source=(\"node\", np.array(edge_df['source'], dtype='int32')),\n",
    "                                          target=(\"node\", np.array(edge_df['target'], dtype='int32')),\n",
    "                                      ))\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return graph_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a236f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = create_graph_tensor(node_df, edge_df)\n",
    "train_tensor = create_graph_tensor(train_node_df, train_edge_df)\n",
    "test_tensor = create_graph_tensor(test_node_df, test_edge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d9c8d",
   "metadata": {},
   "source": [
    "split off ‚Äòhead‚Äô as our target (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a08b1bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_batch_merge(graph):\n",
    "    graph = graph.merge_batch_to_components()\n",
    "    node_features = graph.node_sets['node'].get_features_dict()\n",
    "    edge_features = graph.edge_sets['link'].get_features_dict()\n",
    "\n",
    "    label = node_features.pop('measurement')\n",
    "    print(label)\n",
    "\n",
    "    new_graph = graph.replace_features(node_sets={'node': node_features}, edge_sets={'link': edge_features})\n",
    "    return new_graph, label\n",
    "\n",
    "\n",
    "def create_dataset(graph, function):\n",
    "    dataset = tf.data.Dataset.from_tensors(graph)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset.map(function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a1395",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9d9e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "full_node_dataset = create_dataset(full_tensor, node_batch_merge)\n",
    "train_node_dataset = create_dataset(train_tensor, node_batch_merge)\n",
    "test_node_dataset = create_dataset(test_tensor, node_batch_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d116b20",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a798ce8",
   "metadata": {},
   "source": [
    "## Build model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "498566f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_spec = train_node_dataset.element_spec[0]\n",
    "input_graph = tf.keras.layers.Input(type_spec=graph_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3493ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_node_state(node_set, node_set_name):\n",
    "    features = [\n",
    "        #tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Node_indicator']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Junction_in']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['demand']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Measurement_in']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n",
    "def set_initial_edge_state(edge_set, edge_set_name):\n",
    "    features = [\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(edge_set['loss_co']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814bcb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n"
     ]
    }
   ],
   "source": [
    "graph = tfgnn.keras.layers.MapFeatures(node_sets_fn=set_initial_node_state,\n",
    "                                       edge_sets_fn=set_initial_edge_state)(input_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c29e370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(units=32, l2_reg=0.1, dropout=0.25, activation='relu'):\n",
    "    regularizer = tf.keras.regularizers.l2(l2_reg)\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, kernel_regularizer=regularizer, bias_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(dropout)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8aa450",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1e02fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " map_features (MapFeatures)  ()                        256       \n",
      "                                                                 \n",
      " graph_update (GraphUpdate)  ()                        15456     \n",
      "                                                                 \n",
      " graph_update_1 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_2 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_3 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_4 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_5 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_6 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_7 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_8 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_9 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_10 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_11 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_12 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_13 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_14 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_15 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_16 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_17 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_18 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_19 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_20 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_21 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_22 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_23 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_24 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_25 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_26 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_27 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_28 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_29 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_30 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_31 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_32 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_33 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_34 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_35 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_36 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_37 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_38 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_39 (GraphUpdat  ()                       11360     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " e)                                                              \n",
      "                                                                 \n",
      " input.node_sets_2 (Instance  {'node': ()}             0         \n",
      " Property)                                                       \n",
      "                                                                 \n",
      " input._get_features_ref_6 (  {'hidden_state': (None,   0        \n",
      " InstanceProperty)           64)}                                \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 458,817\n",
      "Trainable params: 458,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "graph_updates = 20\n",
    "for i in range(graph_updates):\n",
    "    graph = tfgnn.keras.layers.GraphUpdate(\n",
    "        node_sets={\n",
    "            'node':\n",
    "            tfgnn.keras.layers.NodeSetUpdate(\n",
    "                {\n",
    "                    'link':\n",
    "                    tfgnn.keras.layers.SimpleConv(message_fn=dense_layer(32),\n",
    "                                                  reduce_type=\"sum\",\n",
    "                                                  sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
    "                                                  receiver_tag=tfgnn.TARGET)\n",
    "                }, tfgnn.keras.layers.NextStateFromConcat(dense_layer(64)))\n",
    "        })(graph)\n",
    "\n",
    "\n",
    "logits = tf.keras.layers.Dense(1)(graph.node_sets[\"node\"][tfgnn.HIDDEN_STATE])\n",
    "\n",
    "node_model = tf.keras.Model(input_graph, logits)\n",
    "node_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                   loss='mean_squared_error',\n",
    "                   metrics=['Accuracy'])\n",
    "node_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3a0112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MapDataset element_spec=(GraphTensorSpec({'context': ContextSpec({'features': {}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'node_sets': {'node': NodeSetSpec({'features': {'Junction_in': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None), 'demand': TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), 'Measurement_in': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None)}, 'edge_sets': {'link': EdgeSetSpec({'features': {'loss_co': TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'node', '#index.1': 'node'})}, TensorShape([]), tf.int32, None)}}, TensorShape([]), tf.int32, None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d63e7b",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a074ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 64s 5s/step - loss: nan - Accuracy: 0.0000e+00 - val_loss: nan - val_Accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      " 4/10 [===========>..................] - ETA: 29s - loss: nan - Accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m es \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mnode_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_node_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_node_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "\n",
    "node_model.fit(train_node_dataset.repeat(),\n",
    "               validation_data=full_node_dataset,\n",
    "               steps_per_epoch=10,\n",
    "               epochs=1000,\n",
    "               callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a36fc",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c51dc1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step - loss: 4705823744.0000 - mean_squared_error: 4705823744.0000\n",
      "{'loss': 4705823744.0, 'mean_squared_error': 4705823744.0}\n"
     ]
    }
   ],
   "source": [
    "eval_result = node_model.evaluate(test_node_dataset)\n",
    "print(dict(zip(node_model.metrics_names, eval_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11f14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
