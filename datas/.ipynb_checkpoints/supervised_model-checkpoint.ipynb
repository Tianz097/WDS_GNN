{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1fbc574",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0107e16",
   "metadata": {},
   "source": [
    "256×169 samples</p>\n",
    "### Change demand\n",
    "timestep = 1h, 1 week ->169 timesteps in total</p>\n",
    "at every timestep, change the nodal demand</p>\n",
    "### Change topology\n",
    "Randomly cut the connectivity between two pipes, but preserving the connectivity between each node in the network and source. ->256 topology\n",
    "\n",
    "### Try single timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9ca9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import numpy as np \n",
    "import random\n",
    "import tqdm\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter \n",
    "import networkx as nx\n",
    "import copy\n",
    "import pandas as pd\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80627a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removable_links(inp_file):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "    removable_links = []\n",
    "    G = wn.to_graph(wn)\n",
    "    # Store not-deadend pipes to be removed\n",
    "    for _, link in wn.links():\n",
    "        if (link.link_type == 'Pipe' and\n",
    "            link.start_node.node_type == 'Junction' and\n",
    "            link.end_node.node_type == 'Junction' and\n",
    "            G.degree[link.start_node.name] > 1 and\n",
    "            G.degree[link.end_node.name] > 1):\n",
    "            removable_links.append(link)\n",
    "    # To find pairs of links that can be removed together while keeping the network graph connected\n",
    "    removable_pairs = []\n",
    "    for (link1, link2) in itertools.combinations(removable_links, 2):\n",
    "        wnr = copy.deepcopy(wn)  #create a new reference to the same object\n",
    "        wnr.remove_link(link1)\n",
    "        wnr.remove_link(link2)\n",
    "        Gr = wnr.to_graph().to_undirected()\n",
    "        if nx.is_connected(Gr):\n",
    "            removable_pairs.append((link1, link2))\n",
    "\n",
    "    return removable_links, removable_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101893f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'ASnet2'\n",
    "inp_file = network + '.inp'\n",
    "wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "\n",
    "# get removable links\n",
    "removable_links, removable_pairs = get_removable_links(inp_file)\n",
    "num_nodes = wn.num_nodes\n",
    "num_links = wn.num_links\n",
    "num_time = 5\n",
    "#num_time = int(wn.options.time.duration / wn.options.time.report_timestep + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47c0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sims = 256\n",
    "#𝑉_𝑖=[ 𝐼_𝑖^𝑑, 𝑞_𝑖, 𝐼_𝑖^𝑚,𝐻_𝑖^∗ ] \n",
    "#𝐸_𝑝=[𝑖,𝑗,𝑐_𝑝]\n",
    "#Create data matrix\n",
    "A = np.zeros((n_sims , num_links*num_time, 3))\n",
    "B = np.zeros((n_sims , num_nodes*num_time, 6))\n",
    "\n",
    "\n",
    "#A = np.zeros((n_sims * num_time, num_links, 3))\n",
    "#B = np.zeros((n_sims * num_time, num_nodes, 4))\n",
    "#U = np.zeros((n_sims * num_time, num_nodes, 1))\n",
    "\n",
    "# Store the randomly chosen pairs of removable links\n",
    "links2remove = random.sample(removable_pairs, n_sims)\n",
    "\n",
    "## Measurement when fully-supervised\n",
    "measurement_fully = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d43e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in range(n_sims):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)  # reset value\n",
    "    wn.options.hydraulic.demand_model = 'DD' #dynamic demand model\n",
    "\n",
    "    i = 0\n",
    "    for _, node in wn.nodes():\n",
    "        node.id = i\n",
    "        i += 1\n",
    "\n",
    "    if sim != 0:\n",
    "        (link1, link2) = links2remove[sim - 1]\n",
    "        wn.remove_link(link1)\n",
    "        wn.remove_link(link2)\n",
    "\n",
    "    i = 0\n",
    "    for _, link in wn.links():\n",
    "        A[sim, i, 0] = link.start_node.id\n",
    "        A[sim, i, 1] = link.end_node.id\n",
    "        A[sim, i, 2] = 1 / (10.667 *link.length / link.roughness ** 1.852 /link.diameter ** 4.871)\n",
    "        i += 1\n",
    "\n",
    "    results = wntr.sim.EpanetSimulator(wn).run_sim(version=2.0)\n",
    "    head = results.node['head']\n",
    "    demand = results.node['demand']\n",
    "    demand = np.maximum(demand, 0)\n",
    "    \n",
    "    ### Produce datas for multiple timestep\n",
    "    #### Time step\n",
    "    index_values = head.index.values\n",
    "    np.random.seed(42)\n",
    "    Time_step = np.random.choice(index_values, size=5, replace=False)\n",
    "    \n",
    "    repeated_timestep = pd.Series(Time_step).repeat(num_nodes).reset_index(drop=True)\n",
    "    Time_indicator = pd.DataFrame({'Timestep': repeated_timestep})\n",
    "    Time_indicator = Time_indicator.squeeze()\n",
    "    \n",
    "    #### Demand\n",
    "    demand_s = demand.loc[Time_step]\n",
    "    demand_s = demand_s.values.flatten()\n",
    "    #### Head\n",
    "    head_s = head.loc[Time_step]\n",
    "    head_s = head_s.values.flatten()\n",
    "    #### Node indicator (the number of the node)\n",
    "    Node_indicator = np.tile(np.arange(1, num_nodes+1), num_time)\n",
    "        # Measurement when fully-supervised\n",
    "    measurement_fully = Node_indicator\n",
    "    #### Junction indicator (if the node is not a reservoir, junction indicator = 1)\n",
    "    Nd_single = np.array([1 if node.node_type == 'Junction' else 0 for _, node in wn.nodes()])\n",
    "    Nd = np.tile(Nd_single,num_time)\n",
    "    Nd = Nd.squeeze()\n",
    "    #### Measurement indicator (if the node has head, measurement indicator = 1) (fully-supervised, all 1)\n",
    "    Nh_single = np.zeros(num_nodes)\n",
    "    Nh = np.tile(Nh_single,num_time)\n",
    "    Nh = Nh.squeeze()\n",
    "    ###\n",
    "    \n",
    "    ### Node\n",
    "    B[sim, :, 0] = Time_indicator\n",
    "    B[sim, :, 1] = Node_indicator\n",
    "    B[sim, :, 2] = Nd\n",
    "    B[sim, :, 3] = demand_s\n",
    "    B[sim, :, 4] = Nh\n",
    "    B[sim, :, 5] = (1 - Nh) * head_s\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa712e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edge\n",
    "A_re = A[:, :65, :]  # Extract the first 65 rows along the second axis\n",
    "\n",
    "# Repeat the 65 rows to cover the entire second axis\n",
    "A_re = np.tile(A_re, (1, num_time, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c92515",
   "metadata": {},
   "source": [
    "### Change 3-d array to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c5ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_3d_shape = B.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "B_2d = B.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "node_df = pd.DataFrame(B_2d)\n",
    "\n",
    "array_3d_shape = A_re.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "A_2d = A_re.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "edge_df = pd.DataFrame(A_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff6cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df.rename(columns={0: 'source', 1: 'target', 2: 'loss_co'},inplace=True)\n",
    "node_df.rename(columns={0:'Time_indicator', 1: 'Node_indicator', 2:'Junction_in',3: 'demand', 4: 'Measurement_in',5:'measurement'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293e0425",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b3f556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_indicator</th>\n",
       "      <th>Node_indicator</th>\n",
       "      <th>Junction_in</th>\n",
       "      <th>demand</th>\n",
       "      <th>Measurement_in</th>\n",
       "      <th>measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>496800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.410048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.044707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>496800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.581834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496800.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.881058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496800.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.244421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.040970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time_indicator  Node_indicator  Junction_in    demand  Measurement_in  \\\n",
       "0        496800.0             1.0          1.0 -0.410048             0.0   \n",
       "1        496800.0             2.0          1.0  0.155513             0.0   \n",
       "2        496800.0             3.0          1.0  1.581834             0.0   \n",
       "3        496800.0             4.0          1.0  2.881058             0.0   \n",
       "4        496800.0             5.0          1.0 -0.244421             0.0   \n",
       "\n",
       "   measurement  \n",
       "0    -0.044707  \n",
       "1    -0.046332  \n",
       "2    -0.045113  \n",
       "3    -0.025940  \n",
       "4    -0.040970  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge\n",
    "## Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Select the column to scale\n",
    "column_to_scale = 'loss_co'\n",
    "\n",
    "## Fit and transform the selected column\n",
    "edge_df[column_to_scale] = scaler.fit_transform(edge_df[[column_to_scale]])\n",
    "#\n",
    "# Node\n",
    "## Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Select the column to scale\n",
    "columns_to_scale = ['demand', 'measurement']\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "node_df[columns_to_scale] = scaler.fit_transform(node_df[columns_to_scale])\n",
    "#\n",
    "\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70f714fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edge_df = edge_df[n_sims*num_links*(num_time-1):]\n",
    "test_node_df = node_df[n_sims*num_nodes*(num_time-1):]\n",
    "\n",
    "train_edge_df = edge_df[:n_sims*num_links*(num_time-1)]\n",
    "train_node_df = node_df[:n_sims*num_nodes*(num_time-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8448eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_tensor(node_df, edge_df):\n",
    "    graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "        node_sets={\n",
    "            \"node\": tfgnn.NodeSet.from_fields(\n",
    "                sizes=[len(node_df)],\n",
    "                features={\n",
    "                    #'Node_indicator':np.array(node_df['Node_indicator'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'Junction_in':np.array(node_df['Junction_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'demand': np.array(node_df['demand'], dtype='float32').reshape(len(node_df),1),\n",
    "                    'Measurement_in': np.array(node_df['Measurement_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'measurement': np.array(node_df['measurement'], dtype='float32').reshape(len(node_df),1),\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        edge_sets={\n",
    "            \"link\": tfgnn.EdgeSet.from_fields(\n",
    "                sizes=[len(edge_df)],\n",
    "                features={\n",
    "                    'loss_co': np.array(edge_df['loss_co'], dtype='float32').reshape(len(edge_df),1),\n",
    "                },\n",
    "                adjacency=tfgnn.Adjacency.from_indices(\n",
    "                                          source=(\"node\", np.array(edge_df['source'], dtype='int32')),\n",
    "                                          target=(\"node\", np.array(edge_df['target'], dtype='int32')),\n",
    "                                      ))\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return graph_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a236f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = create_graph_tensor(node_df, edge_df)\n",
    "train_tensor = create_graph_tensor(train_node_df, train_edge_df)\n",
    "test_tensor = create_graph_tensor(test_node_df, test_edge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d9c8d",
   "metadata": {},
   "source": [
    "split off ‘head’ as our target (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a08b1bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_batch_merge(graph):\n",
    "    graph = graph.merge_batch_to_components()\n",
    "    node_features = graph.node_sets['node'].get_features_dict()\n",
    "    edge_features = graph.edge_sets['link'].get_features_dict()\n",
    "\n",
    "    label = node_features.pop('measurement')\n",
    "    print(label)\n",
    "\n",
    "    new_graph = graph.replace_features(node_sets={'node': node_features}, edge_sets={'link': edge_features})\n",
    "    return new_graph, label\n",
    "\n",
    "\n",
    "def create_dataset(graph, function):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(graph)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset.map(function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a1395",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d9e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "full_node_dataset = create_dataset(full_tensor, node_batch_merge)\n",
    "train_node_dataset = create_dataset(train_tensor, node_batch_merge)\n",
    "test_node_dataset = create_dataset(test_tensor, node_batch_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d116b20",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a798ce8",
   "metadata": {},
   "source": [
    "## Build model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "498566f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_spec = train_node_dataset.element_spec[0]\n",
    "input_graph = tf.keras.layers.Input(type_spec=graph_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3493ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_node_state(node_set, node_set_name):\n",
    "    features = [\n",
    "        #tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Node_indicator']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Junction_in']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['demand']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Measurement_in']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n",
    "def set_initial_edge_state(edge_set, edge_set_name):\n",
    "    features = [\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(edge_set['loss_co']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "814bcb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tfgnn.keras.layers.MapFeatures(node_sets_fn=set_initial_node_state,\n",
    "                                       edge_sets_fn=set_initial_edge_state)(input_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c29e370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(units=32, l2_reg=0.1, dropout=0.25, activation='relu'):\n",
    "    regularizer = tf.keras.regularizers.l2(l2_reg)\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, kernel_regularizer=regularizer, bias_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(dropout)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8aa450",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1e02fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " map_features_3 (MapFeatures  ()                       256       \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_19 (GraphUpdat  ()                       15456     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_20 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_21 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_22 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_23 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " graph_update_24 (GraphUpdat  ()                       11360     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " input.node_sets_8 (Instance  {'node': ()}             0         \n",
      " Property)                                                       \n",
      "                                                                 \n",
      " input._get_features_ref_24   {'hidden_state': (None,   0        \n",
      " (InstanceProperty)          64)}                                \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,577\n",
      "Trainable params: 72,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "graph_updates = 3\n",
    "for i in range(graph_updates):\n",
    "    graph = tfgnn.keras.layers.GraphUpdate(\n",
    "        node_sets={\n",
    "            'node':\n",
    "            tfgnn.keras.layers.NodeSetUpdate(\n",
    "                {\n",
    "                    'link':\n",
    "                    tfgnn.keras.layers.SimpleConv(message_fn=dense_layer(32),\n",
    "                                                  reduce_type=\"sum\",\n",
    "                                                  sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
    "                                                  receiver_tag=tfgnn.TARGET)\n",
    "                }, tfgnn.keras.layers.NextStateFromConcat(dense_layer(64)))\n",
    "        })(graph)\n",
    "\n",
    "\n",
    "logits = tf.keras.layers.Dense(1)(graph.node_sets[\"node\"][tfgnn.HIDDEN_STATE])\n",
    "\n",
    "node_model = tf.keras.Model(input_graph, logits)\n",
    "node_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.000001),\n",
    "                   loss='mean_squared_error',\n",
    "                   metrics=['Accuracy'])\n",
    "node_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3a0112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MapDataset element_spec=(GraphTensorSpec({'context': ContextSpec({'features': {}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None), 'node_sets': {'node': NodeSetSpec({'features': {'Junction_in': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None), 'demand': TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), 'Measurement_in': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, None)}, 'edge_sets': {'link': EdgeSetSpec({'features': {'loss_co': TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)}, 'sizes': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, {'#index.0': 'node', '#index.1': 'node'})}, TensorShape([]), tf.int32, None)}}, TensorShape([]), tf.int32, None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d63e7b",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a074ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  1/100 [..............................] - ETA: 1:15 - loss: nan - Accuracy: 0.0000e+00WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 2s 16ms/step - loss: nan - Accuracy: 0.0000e+00 - val_loss: nan - val_Accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a0d54ef310>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "\n",
    "node_model.fit(train_node_dataset.repeat(),\n",
    "               validation_data=full_node_dataset,\n",
    "               steps_per_epoch=100,\n",
    "               epochs=1000,\n",
    "               callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a36fc",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c51dc1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step - loss: 4705823744.0000 - mean_squared_error: 4705823744.0000\n",
      "{'loss': 4705823744.0, 'mean_squared_error': 4705823744.0}\n"
     ]
    }
   ],
   "source": [
    "eval_result = node_model.evaluate(test_node_dataset)\n",
    "print(dict(zip(node_model.metrics_names, eval_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11677aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
