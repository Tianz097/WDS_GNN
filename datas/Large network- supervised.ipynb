{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0fd60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff3b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import numpy as np \n",
    "import random\n",
    "import tqdm\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter \n",
    "import networkx as nx\n",
    "import copy\n",
    "import pandas as pd\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c06def",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to get all removable links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cd0a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removable_links(inp_file):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "    removable_links = []\n",
    "    G = wn.to_graph(wn)\n",
    "    # Store not-deadend pipes to be removed\n",
    "    for _, link in wn.links():\n",
    "        if (link.link_type == 'Pipe' and\n",
    "            link.start_node.node_type == 'Junction' and\n",
    "            link.end_node.node_type == 'Junction' and\n",
    "            G.degree[link.start_node.name] > 1 and\n",
    "            G.degree[link.end_node.name] > 1):\n",
    "            removable_links.append(link)\n",
    "\n",
    "\n",
    "    return removable_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a3b79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removable_pairs(removable_links,limited_combinations):\n",
    "    removable_pairs = []\n",
    "    \n",
    "    for (link1, link2) in limited_combinations:\n",
    "\n",
    "        wnr = copy.deepcopy(wn)\n",
    "        wnr.remove_link(link1)\n",
    "        wnr.remove_link(link2)\n",
    "        Gr = wnr.to_graph().to_undirected()\n",
    "        if nx.is_connected(Gr):\n",
    "            removable_pairs.append((link1, link2))\n",
    "                \n",
    "    return removable_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bca2d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd469c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'bwflnet_no_control'\n",
    "inp_file = network + '.inp'\n",
    "wn = wntr.network.WaterNetworkModel(inp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7525569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the removable links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81e8e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get removable links\n",
    "removable_links = get_removable_links(inp_file)\n",
    "\n",
    "num_nodes = wn.num_nodes\n",
    "num_links = wn.num_links\n",
    "num_time = 5\n",
    "n_sims = 3\n",
    "#num_time = int(wn.options.time.duration / wn.options.time.report_timestep + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd7b6630",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_combinations = 500\n",
    "limited_combinations = itertools.islice(itertools.combinations(removable_links, 2), n_combinations)\n",
    "removable_pairs = get_removable_pairs(removable_links,limited_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86b1a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((n_sims , num_links*num_time, 3))\n",
    "B = np.zeros((n_sims , num_nodes*num_time, 6))\n",
    "U = np.zeros((n_sims , num_nodes*num_time, 1))\n",
    "# Store the randomly chosen pairs of removable links\n",
    "links2remove = random.sample(removable_pairs, n_sims)\n",
    "\n",
    "## Measurement when fully-supervised\n",
    "measurement_fully = []\n",
    "monitor = ['5', '11', '32', '37', '44']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49254869",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in range(n_sims):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)  # reset value\n",
    "    wn.options.hydraulic.demand_model = 'DD' #dynamic demand model\n",
    "\n",
    "    i = 0\n",
    "    for _, node in wn.nodes():\n",
    "        node.id = i\n",
    "        i += 1\n",
    "\n",
    "    if sim != 0:\n",
    "        (link1, link2) = links2remove[sim - 1]\n",
    "        wn.remove_link(link1)\n",
    "        wn.remove_link(link2)\n",
    "\n",
    "    i = 0\n",
    "    for _, link in wn.links():\n",
    "        A[sim, i, 0] = link.start_node.id\n",
    "        A[sim, i, 1] = link.end_node.id\n",
    "        if link.link_type == \"pipes\":\n",
    "            A[sim, i, 2] = 1 / (10.667 *link.length / link.roughness ** 1.852 /link.diameter ** 4.871)\n",
    "        else:\n",
    "            A[sim, i, 2] = 0\n",
    "        i += 1\n",
    "\n",
    "    results = wntr.sim.EpanetSimulator(wn).run_sim(version=2.0)\n",
    "    head = results.node['head']\n",
    "    demand = results.node['demand']\n",
    "    demand = np.maximum(demand, 0)\n",
    "    \n",
    "    ### Produce datas for multiple timestep\n",
    "    #### Time step\n",
    "    index_values = head.index.values\n",
    "    np.random.seed(42)\n",
    "    Time_step = np.random.choice(index_values, size=num_time, replace=False)\n",
    "    \n",
    "    repeated_timestep = pd.Series(Time_step).repeat(num_nodes).reset_index(drop=True)\n",
    "    Time_indicator = pd.DataFrame({'Timestep': repeated_timestep})\n",
    "    Time_indicator = Time_indicator.squeeze()\n",
    "    \n",
    "    #### Demand\n",
    "    demand_s = demand.loc[Time_step]\n",
    "    demand_s = demand_s.values.flatten()\n",
    "    #### Head\n",
    "    head_s = head.loc[Time_step]\n",
    "    head_s = head_s.values.flatten()\n",
    "    #### Node indicator (the number of the node)\n",
    "    Node_indicator = np.tile(np.arange(1, num_nodes+1), num_time)\n",
    "        # Measurement when fully-supervised\n",
    "    measurement_fully = Node_indicator\n",
    "    #### Junction indicator (if the node is not a reservoir, junction indicator = 1)\n",
    "    Nd_single = np.array([1 if node.node_type == 'Junction' else 0 for _, node in wn.nodes()])\n",
    "    Nd = np.tile(Nd_single,num_time)\n",
    "    Nd = Nd.squeeze()\n",
    "    #### Measurement indicator (if the node has head, measurement indicator = 1) (fully-supervised, all 1)\n",
    "    Nh_single = np.zeros(num_nodes)\n",
    "    Nh = np.tile(Nh_single,num_time)\n",
    "    Nh = Nh.squeeze()\n",
    "    ###\n",
    "    \n",
    "    ### Node\n",
    "    B[sim, :, 0] = Time_indicator\n",
    "    B[sim, :, 1] = Node_indicator\n",
    "    B[sim, :, 2] = Nd\n",
    "    B[sim, :, 3] = demand_s\n",
    "    B[sim, :, 4] = Nh\n",
    "    B[sim, :, 5] = (1 - Nh) * head_s\n",
    "    ###\n",
    "\n",
    "    U[sim, :, 0] = head_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9d90887",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edge\n",
    "A_re = A[:, :num_links, :]  # Extract the first 65 rows along the second axis\n",
    "\n",
    "# Repeat the 65 rows to cover the entire second axis\n",
    "A_re = np.tile(A_re, (1, num_links, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5db2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_3d_shape = B.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "B_2d = B.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "node_df = pd.DataFrame(B_2d)\n",
    "\n",
    "array_3d_shape = A_re.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "A_2d = A_re.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "edge_df = pd.DataFrame(A_2d)\n",
    "\n",
    "array_3d_shape = U.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "U_2d = U.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "graph_df = pd.DataFrame(U_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd8589e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df.rename(columns={0: 'head'},inplace=True)\n",
    "edge_df.rename(columns={0: 'source', 1: 'target', 2: 'loss_co'},inplace=True)\n",
    "node_df.rename(columns={0:'Time_indicator', 1: 'Node_indicator', 2:'Junction_in',3: 'demand', 4: 'Measurement_in',5:'measurement'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "865cb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge\n",
    "## Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Select the column to scale\n",
    "column_to_scale = 'loss_co'\n",
    "\n",
    "## Fit and transform the selected column\n",
    "edge_df[column_to_scale] = scaler.fit_transform(edge_df[[column_to_scale]])\n",
    "#\n",
    "# Node\n",
    "## Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Select the column to scale\n",
    "columns_to_scale = ['demand', 'measurement']\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "node_df[columns_to_scale] = scaler.fit_transform(node_df[columns_to_scale])\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59f4c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edge_df = edge_df[n_sims * num_links * (num_time - 1):]\n",
    "test_node_df = node_df[n_sims * num_nodes * (num_time - 1):]\n",
    "\n",
    "train_edge_df = edge_df[:n_sims * num_links * (num_time - 1)]\n",
    "train_node_df = node_df[:n_sims * num_nodes * (num_time - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2614dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_tensor(node_df, edge_df):\n",
    "    graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "\n",
    "        node_sets={\n",
    "            \"node\": tfgnn.NodeSet.from_fields(\n",
    "                sizes=[len(node_df)],\n",
    "                features={\n",
    "                    #'Node_indicator':np.array(node_df['Node_indicator'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'Junction_in':np.array(node_df['Junction_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'demand': np.array(node_df['demand'], dtype='float32').reshape(len(node_df),1),\n",
    "                    'Measurement_in': np.array(node_df['Measurement_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'measurement': np.array(node_df['measurement'], dtype='float32').reshape(len(node_df),1),\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        edge_sets={\n",
    "            \"link\": tfgnn.EdgeSet.from_fields(\n",
    "                sizes=[len(edge_df)],\n",
    "                features={\n",
    "                    'loss_co': np.array(edge_df['loss_co'], dtype='float32').reshape(len(edge_df),1),\n",
    "                },\n",
    "                adjacency=tfgnn.Adjacency.from_indices(\n",
    "                                          source=(\"node\", np.array(edge_df['source'], dtype='int32')),\n",
    "                                          target=(\"node\", np.array(edge_df['target'], dtype='int32')),\n",
    "                                      ))\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return graph_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c1bbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = create_graph_tensor(node_df, edge_df)\n",
    "train_tensor = create_graph_tensor(train_node_df, train_edge_df)\n",
    "test_tensor = create_graph_tensor(test_node_df, test_edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65049d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_batch_merge(graph):\n",
    "    graph = graph.merge_batch_to_components()\n",
    "    node_features = graph.node_sets['node'].get_features_dict()\n",
    "    edge_features = graph.edge_sets['link'].get_features_dict()\n",
    "    \n",
    "    label = node_features.pop('measurement')\n",
    "    print(label)\n",
    "    new_graph = graph.replace_features(node_sets={'node': node_features}, edge_sets={'link': edge_features})\n",
    "    \n",
    "    return new_graph, label\n",
    "\n",
    "\n",
    "     \n",
    "def create_dataset(graph, function):\n",
    "    dataset = tf.data.Dataset.from_tensors(graph)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset.map(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d51a12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "full_node_dataset = create_dataset(full_tensor, node_batch_merge)\n",
    "train_node_dataset = create_dataset(train_tensor, node_batch_merge)\n",
    "test_node_dataset = create_dataset(test_tensor, node_batch_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b42552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_spec = train_node_dataset.element_spec[0]\n",
    "input_graph = tf.keras.layers.Input(type_spec=graph_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67604f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n"
     ]
    }
   ],
   "source": [
    "def set_initial_node_state(node_set, node_set_name):\n",
    "    features = [\n",
    "        #tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Node_indicator']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Junction_in']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['demand']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Measurement_in']),\n",
    "        #tf.keras.layers.Dense(32, activation=\"relu\")(node_set['measurement']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n",
    "def set_initial_edge_state(edge_set, edge_set_name):\n",
    "    features = [\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(edge_set['loss_co']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n",
    "graph = tfgnn.keras.layers.MapFeatures(node_sets_fn=set_initial_node_state,\n",
    "                                       edge_sets_fn=set_initial_edge_state)(input_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c456585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(units=32, l2_reg=0.1, dropout=0.25, activation='relu'):\n",
    "    regularizer = tf.keras.regularizers.l2(l2_reg)\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, kernel_regularizer=regularizer, bias_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(dropout)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2cd97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_updates = 5\n",
    "for i in range(graph_updates):\n",
    "    graph = tfgnn.keras.layers.GraphUpdate(\n",
    "        node_sets={\n",
    "            'node':\n",
    "            tfgnn.keras.layers.NodeSetUpdate(\n",
    "                {\n",
    "                    'link':\n",
    "                    tfgnn.keras.layers.SimpleConv(message_fn=dense_layer(16),\n",
    "                                                  reduce_type=\"mean\",\n",
    "                                                  sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
    "                                                  receiver_tag=tfgnn.TARGET)\n",
    "                }, tfgnn.keras.layers.NextStateFromConcat(dense_layer(32)))\n",
    "        })(graph)\n",
    "\n",
    "dense1 = tf.keras.layers.Dense(64)(graph.node_sets[\"node\"][tfgnn.HIDDEN_STATE])\n",
    "dense2 = tf.keras.layers.Dense(64)(dense1)\n",
    "dense3 = tf.keras.layers.Dense(1)(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75c407cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " map_features (MapFeatures)  ()                        256       \n",
      "                                                                 \n",
      " graph_update (GraphUpdate)  ()                        7216      \n",
      "                                                                 \n",
      " graph_update_1 (GraphUpdate  ()                       3120      \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_2 (GraphUpdate  ()                       3120      \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_3 (GraphUpdate  ()                       3120      \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_4 (GraphUpdate  ()                       3120      \n",
      " )                                                               \n",
      "                                                                 \n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      " input.node_sets (InstancePr  {'node': ()}             0         \n",
      " operty)                                                         \n",
      "                                                                 \n",
      " input._get_features_ref_4 (  {'hidden_state': (None,   0        \n",
      " InstanceProperty)           32)}                                \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,289\n",
      "Trainable params: 26,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "node_model = tf.keras.Model(input_graph, dense3)\n",
    "node_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                   loss='mean_squared_error',\n",
    "                   metrics=['Accuracy'])\n",
    "node_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf1f2803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 19.9908 - Accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL ResourceExhaustedError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py(377): __init__\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py(52): quick_execute\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py(381): call\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py(1757): _call_flat\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py(966): _call\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py(894): __call__\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py(150): error_handler\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py(2072): evaluate\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py(65): error_handler\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py(1729): fit\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py(65): error_handler\n  C:\\Users\\TianZhang\\AppData\\Local\\Temp\\ipykernel_18548\\1088304893.py(7): <module>\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3460): run_code\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3400): run_ast_nodes\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3221): run_cell_async\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py(129): _pseudo_sync_runner\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3016): _run_cell\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2961): run_cell\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py(531): run_cell\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py(411): do_execute\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py(729): execute_request\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py(406): dispatch_shell\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py(499): process_one\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py(510): dispatch_queue\n  C:\\Users\\TianZhang\\anaconda3\\lib\\asyncio\\events.py(80): _run\n  C:\\Users\\TianZhang\\anaconda3\\lib\\asyncio\\base_events.py(1906): _run_once\n  C:\\Users\\TianZhang\\anaconda3\\lib\\asyncio\\base_events.py(603): run_forever\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py(199): start\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py(711): start\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py(992): launch_instance\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py(17): <module>\n  C:\\Users\\TianZhang\\anaconda3\\lib\\runpy.py(86): _run_code\n  C:\\Users\\TianZhang\\anaconda3\\lib\\runpy.py(196): _run_module_as_main\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m es \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m                                       mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                                       verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      4\u001b[0m                                       patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      5\u001b[0m                                       restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mnode_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_node_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m               \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_node_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m               \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL ResourceExhaustedError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py(377): __init__\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py(52): quick_execute\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py(381): call\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py(1757): _call_flat\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py(966): _call\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py(894): __call__\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py(150): error_handler\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py(2072): evaluate\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py(65): error_handler\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py(1729): fit\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py(65): error_handler\n  C:\\Users\\TianZhang\\AppData\\Local\\Temp\\ipykernel_18548\\1088304893.py(7): <module>\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3460): run_code\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3400): run_ast_nodes\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3221): run_cell_async\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py(129): _pseudo_sync_runner\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3016): _run_cell\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2961): run_cell\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py(531): run_cell\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py(411): do_execute\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py(729): execute_request\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py(406): dispatch_shell\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py(499): process_one\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py(510): dispatch_queue\n  C:\\Users\\TianZhang\\anaconda3\\lib\\asyncio\\events.py(80): _run\n  C:\\Users\\TianZhang\\anaconda3\\lib\\asyncio\\base_events.py(1906): _run_once\n  C:\\Users\\TianZhang\\anaconda3\\lib\\asyncio\\base_events.py(603): run_forever\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py(199): start\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py(711): start\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py(992): launch_instance\n  C:\\Users\\TianZhang\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py(17): <module>\n  C:\\Users\\TianZhang\\anaconda3\\lib\\runpy.py(86): _run_code\n  C:\\Users\\TianZhang\\anaconda3\\lib\\runpy.py(196): _run_module_as_main\n"
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                      mode='min',\n",
    "                                      verbose=1,\n",
    "                                      patience=10,\n",
    "                                      restore_best_weights=True)\n",
    "\n",
    "node_model.fit(train_node_dataset.repeat(),\n",
    "               validation_data=full_node_dataset,\n",
    "               steps_per_epoch=100,\n",
    "               epochs=100,\n",
    "               callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f6914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
