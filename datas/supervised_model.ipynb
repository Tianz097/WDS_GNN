{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1fbc574",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0107e16",
   "metadata": {},
   "source": [
    "256×169 samples</p>\n",
    "### Change demand\n",
    "timestep = 1h, 1 week ->169 timesteps in total</p>\n",
    "at every timestep, change the nodal demand</p>\n",
    "### Change topology\n",
    "Randomly cut the connectivity between two pipes, but preserving the connectivity between each node in the network and source. ->256 topology\n",
    "\n",
    "### Try single timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9ca9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import numpy as np \n",
    "import random\n",
    "import tqdm\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter \n",
    "import networkx as nx\n",
    "import copy\n",
    "import pandas as pd\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80627a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removable_links(inp_file):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "    removable_links = []\n",
    "    G = wn.to_graph(wn)\n",
    "    # Store not-deadend pipes to be removed\n",
    "    for _, link in wn.links():\n",
    "        if (link.link_type == 'Pipe' and\n",
    "            link.start_node.node_type == 'Junction' and\n",
    "            link.end_node.node_type == 'Junction' and\n",
    "            G.degree[link.start_node.name] > 1 and\n",
    "            G.degree[link.end_node.name] > 1):\n",
    "            removable_links.append(link)\n",
    "    # To find pairs of links that can be removed together while keeping the network graph connected\n",
    "    removable_pairs = []\n",
    "    for (link1, link2) in itertools.combinations(removable_links, 2):\n",
    "        wnr = copy.deepcopy(wn)  #create a new reference to the same object\n",
    "        wnr.remove_link(link1)\n",
    "        wnr.remove_link(link2)\n",
    "        Gr = wnr.to_graph().to_undirected()\n",
    "        if nx.is_connected(Gr):\n",
    "            removable_pairs.append((link1, link2))\n",
    "\n",
    "    return removable_links, removable_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101893f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'ASnet2'\n",
    "inp_file = network + '.inp'\n",
    "wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "\n",
    "# get removable links\n",
    "removable_links, removable_pairs = get_removable_links(inp_file)\n",
    "num_nodes = wn.num_nodes\n",
    "num_links = wn.num_links\n",
    "num_time = 5\n",
    "#num_time = int(wn.options.time.duration / wn.options.time.report_timestep + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47c0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sims = 256\n",
    "#𝑉_𝑖=[ 𝐼_𝑖^𝑑, 𝑞_𝑖, 𝐼_𝑖^𝑚,𝐻_𝑖^∗ ] \n",
    "#𝐸_𝑝=[𝑖,𝑗,𝑐_𝑝]\n",
    "#Create data matrix\n",
    "A = np.zeros((n_sims , num_links*num_time, 3))\n",
    "B = np.zeros((n_sims , num_nodes*num_time, 6))\n",
    "\n",
    "\n",
    "#A = np.zeros((n_sims * num_time, num_links, 3))\n",
    "#B = np.zeros((n_sims * num_time, num_nodes, 4))\n",
    "#U = np.zeros((n_sims * num_time, num_nodes, 1))\n",
    "\n",
    "# Store the randomly chosen pairs of removable links\n",
    "links2remove = random.sample(removable_pairs, n_sims)\n",
    "\n",
    "## Measurement when fully-supervised\n",
    "measurement_fully = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d43e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in range(n_sims):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)  # reset value\n",
    "    wn.options.hydraulic.demand_model = 'DD' #dynamic demand model\n",
    "\n",
    "    i = 0\n",
    "    for _, node in wn.nodes():\n",
    "        node.id = i\n",
    "        i += 1\n",
    "\n",
    "    if sim != 0:\n",
    "        (link1, link2) = links2remove[sim - 1]\n",
    "        wn.remove_link(link1)\n",
    "        wn.remove_link(link2)\n",
    "\n",
    "    i = 0\n",
    "    for _, link in wn.links():\n",
    "        A[sim, i, 0] = link.start_node.id\n",
    "        A[sim, i, 1] = link.end_node.id\n",
    "        A[sim, i, 2] = 1 / (10.667 *link.length / link.roughness ** 1.852 /link.diameter ** 4.871)\n",
    "        i += 1\n",
    "\n",
    "    results = wntr.sim.EpanetSimulator(wn).run_sim(version=2.0)\n",
    "    head = results.node['head']\n",
    "    demand = results.node['demand']\n",
    "    demand = np.maximum(demand, 0)\n",
    "    \n",
    "    ### Produce datas for multiple timestep\n",
    "    #### Time step\n",
    "    index_values = head.index.values\n",
    "    np.random.seed(42)\n",
    "    Time_step = np.random.choice(index_values, size=5, replace=False)\n",
    "    \n",
    "    repeated_timestep = pd.Series(Time_step).repeat(num_nodes).reset_index(drop=True)\n",
    "    Time_indicator = pd.DataFrame({'Timestep': repeated_timestep})\n",
    "    Time_indicator = Time_indicator.squeeze()\n",
    "    \n",
    "    #### Demand\n",
    "    demand_s = demand.loc[Time_step]\n",
    "    demand_s = demand_s.values.flatten()\n",
    "    #### Head\n",
    "    head_s = head.loc[Time_step]\n",
    "    head_s = head_s.values.flatten()\n",
    "    #### Node indicator (the number of the node)\n",
    "    Node_indicator = np.tile(np.arange(1, num_nodes+1), num_time)\n",
    "        # Measurement when fully-supervised\n",
    "    measurement_fully = Node_indicator\n",
    "    #### Junction indicator (if the node is not a reservoir, junction indicator = 1)\n",
    "    Nd_single = np.array([1 if node.node_type == 'Junction' else 0 for _, node in wn.nodes()])\n",
    "    Nd = np.tile(Nd_single,num_time)\n",
    "    Nd = Nd.squeeze()\n",
    "    #### Measurement indicator (if the node has head, measurement indicator = 1) (fully-supervised, all 1)\n",
    "    Nh_single = np.zeros(num_nodes)\n",
    "    Nh = np.tile(Nh_single,num_time)\n",
    "    Nh = Nh.squeeze()\n",
    "    ###\n",
    "    \n",
    "    ### Node\n",
    "    B[sim, :, 0] = Time_indicator\n",
    "    B[sim, :, 1] = Node_indicator\n",
    "    B[sim, :, 2] = Nd\n",
    "    B[sim, :, 3] = demand_s\n",
    "    B[sim, :, 4] = Nh\n",
    "    B[sim, :, 5] = (1 - Nh) * head_s\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa712e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edge\n",
    "A_re = A[:, :65, :]  # Extract the first 65 rows along the second axis\n",
    "\n",
    "# Repeat the 65 rows to cover the entire second axis\n",
    "A_re = np.tile(A_re, (1, num_time, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce66191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>loss_co</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.058681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.031799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.084957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.033094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.058681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.031799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.084957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.033094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    source  target   loss_co\n",
       "0      0.0     1.0  0.044470\n",
       "1      1.0     2.0  0.058681\n",
       "2      2.0     3.0  0.031799\n",
       "3      0.0     4.0  0.084957\n",
       "4      2.0    48.0  0.033094\n",
       "..     ...     ...       ...\n",
       "65     0.0     1.0  0.044470\n",
       "66     1.0     2.0  0.058681\n",
       "67     2.0     3.0  0.031799\n",
       "68     0.0     4.0  0.084957\n",
       "69     2.0    48.0  0.033094\n",
       "\n",
       "[70 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df.head(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c92515",
   "metadata": {},
   "source": [
    "### Change 3-d array to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c5ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_3d_shape = B.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "B_2d = B.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "node_df = pd.DataFrame(B_2d)\n",
    "\n",
    "array_3d_shape = A_re.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "A_2d = A_re.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "edge_df = pd.DataFrame(A_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff6cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df.rename(columns={0: 'source', 1: 'target', 2: 'loss_co'},inplace=True)\n",
    "node_df.rename(columns={0:'Time_indicator', 1: 'Node_indicator', 2:'Junction_in',3: 'demand', 4: 'Measurement_in',5:'measurement'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f714fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edge_df = edge_df[n_sims*num_links*(num_time-1):]\n",
    "test_node_df = node_df[n_sims*num_nodes*(num_time-1):]\n",
    "\n",
    "train_edge_df = edge_df[:n_sims*num_links*(num_time-1)]\n",
    "train_node_df = node_df[:n_sims*num_nodes*(num_time-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8448eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_tensor(node_df, edge_df):\n",
    "    graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "        node_sets={\n",
    "            \"node\": tfgnn.NodeSet.from_fields(\n",
    "                sizes=[len(node_df)],\n",
    "                features={\n",
    "                    #'Node_indicator':np.array(node_df['Node_indicator'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'Junction_in':np.array(node_df['Junction_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'demand': np.array(node_df['demand'], dtype='float32').reshape(len(node_df),1),\n",
    "                    'Measurement_in': np.array(node_df['Measurement_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'measurement': np.array(node_df['measurement'], dtype='float32').reshape(len(node_df),1),\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        edge_sets={\n",
    "            \"link\": tfgnn.EdgeSet.from_fields(\n",
    "                sizes=[len(edge_df)],\n",
    "                features={\n",
    "                    'loss_co': np.array(edge_df['loss_co'], dtype='float32').reshape(len(edge_df),1),\n",
    "                },\n",
    "                adjacency=tfgnn.Adjacency.from_indices(\n",
    "                                          source=(\"node\", np.array(edge_df['source'], dtype='int32')),\n",
    "                                          target=(\"node\", np.array(edge_df['target'], dtype='int32')),\n",
    "                                      ))\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return graph_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a236f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = create_graph_tensor(node_df, edge_df)\n",
    "train_tensor = create_graph_tensor(train_node_df, train_edge_df)\n",
    "test_tensor = create_graph_tensor(test_node_df, test_edge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d9c8d",
   "metadata": {},
   "source": [
    "split off ‘head’ as our target (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a08b1bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_batch_merge(graph):\n",
    "    graph = graph.merge_batch_to_components()\n",
    "    node_features = graph.node_sets['node'].get_features_dict()\n",
    "    edge_features = graph.edge_sets['link'].get_features_dict()\n",
    "\n",
    "    label = node_features.pop('measurement')\n",
    "    print(label)\n",
    "\n",
    "    new_graph = graph.replace_features(node_sets={'node': node_features}, edge_sets={'link': edge_features})\n",
    "    return new_graph, label\n",
    "\n",
    "\n",
    "def create_dataset(graph, function):\n",
    "    dataset = tf.data.Dataset.from_tensors(graph)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset.map(function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a1395",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d9e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "full_node_dataset = create_dataset(full_tensor, node_batch_merge)\n",
    "train_node_dataset = create_dataset(train_tensor, node_batch_merge)\n",
    "test_node_dataset = create_dataset(test_tensor, node_batch_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d116b20",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a798ce8",
   "metadata": {},
   "source": [
    "## Build model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "498566f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_spec = train_node_dataset.element_spec[0]\n",
    "input_graph = tf.keras.layers.Input(type_spec=graph_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3493ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_node_state(node_set, node_set_name):\n",
    "    features = [\n",
    "        #tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Node_indicator']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Junction_in']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['demand']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Measurement_in']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n",
    "def set_initial_edge_state(edge_set, edge_set_name):\n",
    "    features = [\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(edge_set['loss_co']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "814bcb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n"
     ]
    }
   ],
   "source": [
    "graph = tfgnn.keras.layers.MapFeatures(node_sets_fn=set_initial_node_state,\n",
    "                                       edge_sets_fn=set_initial_edge_state)(input_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c29e370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(units=32, l2_reg=0.1, dropout=0.25, activation='relu'):\n",
    "    regularizer = tf.keras.regularizers.l2(l2_reg)\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, kernel_regularizer=regularizer, bias_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(dropout)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8aa450",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1e02fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " map_features_1 (MapFeatures  ()                       256       \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update (GraphUpdate)  ()                        15456     \n",
      "                                                                 \n",
      " graph_update_1 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      " graph_update_2 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      " input.node_sets (InstancePr  {'node': ()}             0         \n",
      " operty)                                                         \n",
      "                                                                 \n",
      " input._get_features_ref_5 (  {'hidden_state': (None,   0        \n",
      " InstanceProperty)           64)}                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,497\n",
      "Trainable params: 38,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "graph_updates = 3\n",
    "for i in range(graph_updates):\n",
    "    graph = tfgnn.keras.layers.GraphUpdate(\n",
    "        node_sets={\n",
    "            'node':\n",
    "            tfgnn.keras.layers.NodeSetUpdate(\n",
    "                {\n",
    "                    'link':\n",
    "                    tfgnn.keras.layers.SimpleConv(message_fn=dense_layer(32),\n",
    "                                                  reduce_type=\"sum\",\n",
    "                                                  sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
    "                                                  receiver_tag=tfgnn.TARGET)\n",
    "                }, tfgnn.keras.layers.NextStateFromConcat(dense_layer(64)))\n",
    "        })(graph)\n",
    "\n",
    "\n",
    "logits = tf.keras.layers.Dense(1)(graph.node_sets[\"node\"][tfgnn.HIDDEN_STATE])\n",
    "\n",
    "node_model = tf.keras.Model(input_graph, logits)\n",
    "node_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                   loss='mean_squared_error',\n",
    "                   metrics=['mean_squared_error'])\n",
    "node_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0112f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d63e7b",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a074ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 5s 304ms/step - loss: 1317883871232000.0000 - mean_squared_error: 1317884005449728.0000 - val_loss: 140075098701824.0000 - val_mean_squared_error: 140075098701824.0000\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 3s 280ms/step - loss: 600725600075776.0000 - mean_squared_error: 600725600075776.0000 - val_loss: 70389489205248.0000 - val_mean_squared_error: 70389489205248.0000\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 160270999617536.0000 - mean_squared_error: 160270999617536.0000 - val_loss: 11942175440896.0000 - val_mean_squared_error: 11942175440896.0000\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 31712916537344.0000 - mean_squared_error: 31712916537344.0000 - val_loss: 10444839321600.0000 - val_mean_squared_error: 10444839321600.0000\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 9462168420352.0000 - mean_squared_error: 9462168420352.0000 - val_loss: 1695078154240.0000 - val_mean_squared_error: 1695078154240.0000\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 5129235857408.0000 - mean_squared_error: 5129235857408.0000 - val_loss: 5107150749696.0000 - val_mean_squared_error: 5107150749696.0000\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 4149237252096.0000 - mean_squared_error: 4149237252096.0000 - val_loss: 247739301888.0000 - val_mean_squared_error: 247739301888.0000\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 3s 292ms/step - loss: 2114614591488.0000 - mean_squared_error: 2114614591488.0000 - val_loss: 380154085376.0000 - val_mean_squared_error: 380154085376.0000\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 3s 297ms/step - loss: 3167380832256.0000 - mean_squared_error: 3167380832256.0000 - val_loss: 105192054784.0000 - val_mean_squared_error: 105192054784.0000\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 1383045660672.0000 - mean_squared_error: 1383045660672.0000 - val_loss: 53546213376.0000 - val_mean_squared_error: 53546213376.0000\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 817023811584.0000 - mean_squared_error: 817023811584.0000 - val_loss: 44441018368.0000 - val_mean_squared_error: 44441018368.0000\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 1055741313024.0000 - mean_squared_error: 1055741313024.0000 - val_loss: 182950920192.0000 - val_mean_squared_error: 182950920192.0000\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 1003550670848.0000 - mean_squared_error: 1003550670848.0000 - val_loss: 70289260544.0000 - val_mean_squared_error: 70289260544.0000\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 1432716050432.0000 - mean_squared_error: 1432716050432.0000 - val_loss: 46692368384.0000 - val_mean_squared_error: 46692368384.0000\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 785502175232.0000 - mean_squared_error: 785502175232.0000 - val_loss: 7946851840.0000 - val_mean_squared_error: 7946851840.0000\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 820092141568.0000 - mean_squared_error: 820092141568.0000 - val_loss: 29514020864.0000 - val_mean_squared_error: 29514020864.0000\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 3s 311ms/step - loss: 693616115712.0000 - mean_squared_error: 693616115712.0000 - val_loss: 32589938688.0000 - val_mean_squared_error: 32589938688.0000\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 529775296512.0000 - mean_squared_error: 529775296512.0000 - val_loss: 122890592256.0000 - val_mean_squared_error: 122890592256.0000\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 622207959040.0000 - mean_squared_error: 622207959040.0000 - val_loss: 8716032000.0000 - val_mean_squared_error: 8716032000.0000\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 730275184640.0000 - mean_squared_error: 730275184640.0000 - val_loss: 13962095616.0000 - val_mean_squared_error: 13962095616.0000\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 935335165952.0000 - mean_squared_error: 935335165952.0000 - val_loss: 4146654208.0000 - val_mean_squared_error: 4146654208.0000\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 373209104384.0000 - mean_squared_error: 373209104384.0000 - val_loss: 20481810432.0000 - val_mean_squared_error: 20481810432.0000\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 494945271808.0000 - mean_squared_error: 494945271808.0000 - val_loss: 87991566336.0000 - val_mean_squared_error: 87991566336.0000\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 6s 619ms/step - loss: 426000220160.0000 - mean_squared_error: 426000220160.0000 - val_loss: 12412013568.0000 - val_mean_squared_error: 12412013568.0000\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 6s 545ms/step - loss: 250158120960.0000 - mean_squared_error: 250158120960.0000 - val_loss: 14341379072.0000 - val_mean_squared_error: 14341379072.0000\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 5s 458ms/step - loss: 265577086976.0000 - mean_squared_error: 265577086976.0000 - val_loss: 29801535488.0000 - val_mean_squared_error: 29801535488.0000\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 318953521152.0000 - mean_squared_error: 318953553920.0000 - val_loss: 3789409280.0000 - val_mean_squared_error: 3789409280.0000\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 4s 440ms/step - loss: 327365066752.0000 - mean_squared_error: 327365066752.0000 - val_loss: 6052612608.0000 - val_mean_squared_error: 6052612608.0000\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 4s 451ms/step - loss: 370035687424.0000 - mean_squared_error: 370035687424.0000 - val_loss: 34377129984.0000 - val_mean_squared_error: 34377129984.0000\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 356996087808.0000 - mean_squared_error: 356996087808.0000 - val_loss: 6459653632.0000 - val_mean_squared_error: 6459653632.0000\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 167822065664.0000 - mean_squared_error: 167822065664.0000 - val_loss: 135577788416.0000 - val_mean_squared_error: 135577788416.0000\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 4s 439ms/step - loss: 360880865280.0000 - mean_squared_error: 360880865280.0000 - val_loss: 134506496000.0000 - val_mean_squared_error: 134506496000.0000\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 198134382592.0000 - mean_squared_error: 198134382592.0000 - val_loss: 6018469888.0000 - val_mean_squared_error: 6018469888.0000\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 4s 412ms/step - loss: 208079028224.0000 - mean_squared_error: 208079028224.0000 - val_loss: 47167975424.0000 - val_mean_squared_error: 47167975424.0000\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 273625579520.0000 - mean_squared_error: 273625579520.0000 - val_loss: 27070816256.0000 - val_mean_squared_error: 27070816256.0000\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 181863120896.0000 - mean_squared_error: 181863120896.0000 - val_loss: 7754114560.0000 - val_mean_squared_error: 7754114560.0000\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 216059871232.0000 - mean_squared_error: 216059871232.0000 - val_loss: 9294248960.0000 - val_mean_squared_error: 9294248960.0000\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 361833660416.0000 - mean_squared_error: 361833693184.0000 - val_loss: 1686717568.0000 - val_mean_squared_error: 1686717568.0000\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 214938091520.0000 - mean_squared_error: 214938091520.0000 - val_loss: 15323787264.0000 - val_mean_squared_error: 15323787264.0000\n",
      "Epoch 40/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 429ms/step - loss: 270177091584.0000 - mean_squared_error: 270177091584.0000 - val_loss: 3570403584.0000 - val_mean_squared_error: 3570403584.0000\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 141449691136.0000 - mean_squared_error: 141449691136.0000 - val_loss: 18311479296.0000 - val_mean_squared_error: 18311479296.0000\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 4s 391ms/step - loss: 169649717248.0000 - mean_squared_error: 169649717248.0000 - val_loss: 805395904.0000 - val_mean_squared_error: 805395904.0000\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 157640425472.0000 - mean_squared_error: 157640425472.0000 - val_loss: 3913114880.0000 - val_mean_squared_error: 3913114880.0000\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 4s 426ms/step - loss: 154708312064.0000 - mean_squared_error: 154708312064.0000 - val_loss: 1288013312.0000 - val_mean_squared_error: 1288013312.0000\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 4s 409ms/step - loss: 170298114048.0000 - mean_squared_error: 170298097664.0000 - val_loss: 4347633664.0000 - val_mean_squared_error: 4347633664.0000\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 4s 409ms/step - loss: 123043725312.0000 - mean_squared_error: 123043733504.0000 - val_loss: 17676210176.0000 - val_mean_squared_error: 17676210176.0000\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 132489723904.0000 - mean_squared_error: 132489723904.0000 - val_loss: 11545003008.0000 - val_mean_squared_error: 11545003008.0000\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 4s 431ms/step - loss: 123879923712.0000 - mean_squared_error: 123879923712.0000 - val_loss: 11857786880.0000 - val_mean_squared_error: 11857786880.0000\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 128633700352.0000 - mean_squared_error: 128633700352.0000 - val_loss: 5663435776.0000 - val_mean_squared_error: 5663435776.0000\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 192555941888.0000 - mean_squared_error: 192555941888.0000 - val_loss: 3123253760.0000 - val_mean_squared_error: 3123253760.0000\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 111583084544.0000 - mean_squared_error: 111583084544.0000 - val_loss: 32583921664.0000 - val_mean_squared_error: 32583921664.0000\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 192688881664.0000 - mean_squared_error: 192688881664.0000 - val_loss: 8518878208.0000 - val_mean_squared_error: 8518878208.0000\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 4s 403ms/step - loss: 121893314560.0000 - mean_squared_error: 121893314560.0000 - val_loss: 563647616.0000 - val_mean_squared_error: 563647616.0000\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 180979367936.0000 - mean_squared_error: 180979367936.0000 - val_loss: 9436567552.0000 - val_mean_squared_error: 9436567552.0000\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 116125442048.0000 - mean_squared_error: 116125442048.0000 - val_loss: 346684768.0000 - val_mean_squared_error: 346684736.0000\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 122518962176.0000 - mean_squared_error: 122518962176.0000 - val_loss: 2655903488.0000 - val_mean_squared_error: 2655903488.0000\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 136493957120.0000 - mean_squared_error: 136493957120.0000 - val_loss: 649564928.0000 - val_mean_squared_error: 649564928.0000\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 94437646336.0000 - mean_squared_error: 94437646336.0000 - val_loss: 1479425920.0000 - val_mean_squared_error: 1479425920.0000\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 4s 409ms/step - loss: 72409980928.0000 - mean_squared_error: 72409980928.0000 - val_loss: 957058880.0000 - val_mean_squared_error: 957058880.0000\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 4s 409ms/step - loss: 83050323968.0000 - mean_squared_error: 83050323968.0000 - val_loss: 3569184000.0000 - val_mean_squared_error: 3569184000.0000\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 83044057088.0000 - mean_squared_error: 83044057088.0000 - val_loss: 2897457920.0000 - val_mean_squared_error: 2897457920.0000\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 55021248512.0000 - mean_squared_error: 55021248512.0000 - val_loss: 1065779648.0000 - val_mean_squared_error: 1065779648.0000\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 135052279808.0000 - mean_squared_error: 135052279808.0000 - val_loss: 17327304704.0000 - val_mean_squared_error: 17327304704.0000\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 4s 438ms/step - loss: 89210634240.0000 - mean_squared_error: 89210634240.0000 - val_loss: 4415777280.0000 - val_mean_squared_error: 4415777280.0000\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 61551194112.0000 - mean_squared_error: 61551194112.0000 - val_loss: 8510949888.0000 - val_mean_squared_error: 8510949888.0000\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 77269114880.0000 - mean_squared_error: 77269114880.0000 - val_loss: 11339465728.0000 - val_mean_squared_error: 11339465728.0000\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 54857412608.0000 - mean_squared_error: 54857412608.0000 - val_loss: 1356339968.0000 - val_mean_squared_error: 1356339968.0000\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 4s 439ms/step - loss: 45151457280.0000 - mean_squared_error: 45151457280.0000 - val_loss: 2126609920.0000 - val_mean_squared_error: 2126609920.0000\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 61193584640.0000 - mean_squared_error: 61193584640.0000 - val_loss: 2857825536.0000 - val_mean_squared_error: 2857825536.0000\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 53368610816.0000 - mean_squared_error: 53368610816.0000 - val_loss: 3858689024.0000 - val_mean_squared_error: 3858689024.0000\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 50304217088.0000 - mean_squared_error: 50304217088.0000 - val_loss: 5915156992.0000 - val_mean_squared_error: 5915156992.0000\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 4s 423ms/step - loss: 45281320960.0000 - mean_squared_error: 45281320960.0000 - val_loss: 2031498112.0000 - val_mean_squared_error: 2031498112.0000\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 4s 433ms/step - loss: 54263496704.0000 - mean_squared_error: 54263496704.0000 - val_loss: 3330675712.0000 - val_mean_squared_error: 3330675712.0000\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 108460351488.0000 - mean_squared_error: 108460351488.0000 - val_loss: 753864704.0000 - val_mean_squared_error: 753864704.0000\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 46756909056.0000 - mean_squared_error: 46756909056.0000 - val_loss: 10606480384.0000 - val_mean_squared_error: 10606480384.0000\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 43436412928.0000 - mean_squared_error: 43436412928.0000 - val_loss: 14369139712.0000 - val_mean_squared_error: 14369139712.0000\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 4s 442ms/step - loss: 66927493120.0000 - mean_squared_error: 66927493120.0000 - val_loss: 986484032.0000 - val_mean_squared_error: 986484032.0000\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 4s 424ms/step - loss: 52868915200.0000 - mean_squared_error: 52868915200.0000 - val_loss: 8346629120.0000 - val_mean_squared_error: 8346629120.0000\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 4s 436ms/step - loss: 56839397376.0000 - mean_squared_error: 56839397376.0000 - val_loss: 1169751552.0000 - val_mean_squared_error: 1169751552.0000\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 446ms/step - loss: 80969760768.0000 - mean_squared_error: 80969760768.0000 - val_loss: 3699984640.0000 - val_mean_squared_error: 3699984640.0000\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 4s 445ms/step - loss: 66899025920.0000 - mean_squared_error: 66899025920.0000 - val_loss: 545622208.0000 - val_mean_squared_error: 545622208.0000\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 48355504128.0000 - mean_squared_error: 48355500032.0000 - val_loss: 7794520064.0000 - val_mean_squared_error: 7794520064.0000\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 39639506944.0000 - mean_squared_error: 39639506944.0000 - val_loss: 1932137472.0000 - val_mean_squared_error: 1932137472.0000\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 34639355904.0000 - mean_squared_error: 34639355904.0000 - val_loss: 2998423808.0000 - val_mean_squared_error: 2998423808.0000\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 52962783232.0000 - mean_squared_error: 52962787328.0000 - val_loss: 5258312704.0000 - val_mean_squared_error: 5258312704.0000\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 59645968384.0000 - mean_squared_error: 59645968384.0000 - val_loss: 5988950016.0000 - val_mean_squared_error: 5988950016.0000\n",
      "Epoch 87/1000\n",
      " 7/10 [====================>.........] - ETA: 1s - loss: 64381202432.0000 - mean_squared_error: 64381202432.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m es \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mnode_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_node_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_node_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50, restore_best_weights=True)\n",
    "\n",
    "node_model.fit(train_node_dataset.repeat(),\n",
    "               validation_data=full_node_dataset,\n",
    "               steps_per_epoch=10,\n",
    "               epochs=1000,\n",
    "               callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a36fc",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c51dc1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step - loss: 4705823744.0000 - mean_squared_error: 4705823744.0000\n",
      "{'loss': 4705823744.0, 'mean_squared_error': 4705823744.0}\n"
     ]
    }
   ],
   "source": [
    "eval_result = node_model.evaluate(test_node_dataset)\n",
    "print(dict(zip(node_model.metrics_names, eval_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11677aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
