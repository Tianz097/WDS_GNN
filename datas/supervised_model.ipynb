{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1fbc574",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0107e16",
   "metadata": {},
   "source": [
    "256×169 samples</p>\n",
    "### Change demand\n",
    "timestep = 1h, 1 week ->169 timesteps in total</p>\n",
    "at every timestep, change the nodal demand</p>\n",
    "### Change topology\n",
    "Randomly cut the connectivity between two pipes, but preserving the connectivity between each node in the network and source. ->256 topology\n",
    "\n",
    "### Try single timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9ca9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wntr\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import numpy as np \n",
    "import random\n",
    "import tqdm\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter \n",
    "import networkx as nx\n",
    "import copy\n",
    "import pandas as pd\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80627a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removable_links(inp_file):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "    removable_links = []\n",
    "    G = wn.to_graph(wn)\n",
    "    # Store not-deadend pipes to be removed\n",
    "    for _, link in wn.links():\n",
    "        if (link.link_type == 'Pipe' and\n",
    "            link.start_node.node_type == 'Junction' and\n",
    "            link.end_node.node_type == 'Junction' and\n",
    "            G.degree[link.start_node.name] > 1 and\n",
    "            G.degree[link.end_node.name] > 1):\n",
    "            removable_links.append(link)\n",
    "    # To find pairs of links that can be removed together while keeping the network graph connected\n",
    "    removable_pairs = []\n",
    "    for (link1, link2) in itertools.combinations(removable_links, 2):\n",
    "        wnr = copy.deepcopy(wn)  #create a new reference to the same object\n",
    "        wnr.remove_link(link1)\n",
    "        wnr.remove_link(link2)\n",
    "        Gr = wnr.to_graph().to_undirected()\n",
    "        if nx.is_connected(Gr):\n",
    "            removable_pairs.append((link1, link2))\n",
    "\n",
    "    return removable_links, removable_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101893f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'ASnet2'\n",
    "inp_file = network + '.inp'\n",
    "wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "\n",
    "# get removable links\n",
    "removable_links, removable_pairs = get_removable_links(inp_file)\n",
    "num_nodes = wn.num_nodes\n",
    "num_links = wn.num_links\n",
    "num_time = int(wn.options.time.duration / wn.options.time.report_timestep + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47c0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sims = 256\n",
    "#𝑉_𝑖=[ 𝐼_𝑖^𝑑, 𝑞_𝑖, 𝐼_𝑖^𝑚,𝐻_𝑖^∗ ] \n",
    "#𝐸_𝑝=[𝑖,𝑗,𝑐_𝑝]\n",
    "#Create data matrix\n",
    "A = np.zeros((n_sims , num_links, 3))\n",
    "B = np.zeros((n_sims , num_nodes, 5))\n",
    "#U = np.zeros((n_sims , num_nodes, 1))\n",
    "\n",
    "\n",
    "#A = np.zeros((n_sims * num_time, num_links, 3))\n",
    "#B = np.zeros((n_sims * num_time, num_nodes, 4))\n",
    "#U = np.zeros((n_sims * num_time, num_nodes, 1))\n",
    "\n",
    "# Store the randomly chosen pairs of removable links\n",
    "links2remove = random.sample(removable_pairs, n_sims)\n",
    "\n",
    "monitor = ['5', '11', '32', '37', '44']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d43e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in range(n_sims):\n",
    "    wn = wntr.network.WaterNetworkModel(inp_file)  # reset value\n",
    "    wn.options.hydraulic.demand_model = 'DD' #dynamic demand model\n",
    "\n",
    "    i = 0\n",
    "    for _, node in wn.nodes():\n",
    "        node.id = i\n",
    "        i += 1\n",
    "\n",
    "    if sim != 0:\n",
    "        (link1, link2) = links2remove[sim - 1]\n",
    "        wn.remove_link(link1)\n",
    "        wn.remove_link(link2)\n",
    "\n",
    "    i = 0\n",
    "    for _, link in wn.links():\n",
    "        A[sim, i, 0] = link.start_node.id\n",
    "        A[sim, i, 1] = link.end_node.id\n",
    "        A[sim, i, 2] = 1 / (10.667 *link.length / link.roughness ** 1.852 /link.diameter ** 4.871)\n",
    "        i += 1\n",
    "        #A[sim * num_time: (sim + 1) * num_time, i, 0] = link.start_node.id\n",
    "        #A[sim * num_time: (sim + 1) * num_time, i, 1] = link.end_node.id\n",
    "        #A[sim * num_time: (sim + 1) * num_time, i, 2] = 1 / (10.667 *\n",
    "                                                           # link.length / link.roughness ** 1.852 /\n",
    "                                                           # link.diameter ** 4.871)\n",
    "        #i += 1\n",
    "    results = wntr.sim.EpanetSimulator(wn).run_sim(version=2.0)\n",
    "    head = results.node['head']\n",
    "    demand = results.node['demand']\n",
    "    demand = np.maximum(demand, 0)\n",
    "    #### Single timestep\n",
    "    demand_s = demand.loc[3600]\n",
    "    head_s = head.loc[3600]\n",
    "    #####\n",
    "    Nd = np.array([1 if node.node_type == 'Junction'\n",
    "                   else 0 for _, node in wn.nodes()])\n",
    "    Nh = np.array([1 if node.node_type == 'Junction' and node.name not in monitor else 0 for _, node in wn.nodes()])\n",
    "    B[sim, :, 0] = Nd\n",
    "    B[sim, :, 1] = demand_s\n",
    "    B[sim, :, 2] = Nh\n",
    "    B[sim, :, 3] = (1 - Nh) * head_s\n",
    "    B[sim, :, 4] = head_s\n",
    "\n",
    "    data_dir = 'datasets/asnet2/enforce_5_b4/'\n",
    "\n",
    "    dataset = {'A': A, 'B': B}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c92515",
   "metadata": {},
   "source": [
    "### Change 3-d array to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c5ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your 3-dimensional NumPy array is called 'array_3d'\n",
    "array_3d_shape = B.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "B_2d = B.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "node_df = pd.DataFrame(B_2d)\n",
    "\n",
    "array_3d_shape = A.shape\n",
    "new_shape = (array_3d_shape[0]* array_3d_shape[1] ,array_3d_shape[2])\n",
    "\n",
    "# Reshaping the 3-dimensional array into a 2-dimensional array\n",
    "A_2d = A.reshape(new_shape)\n",
    "\n",
    "# Converting the 2-dimensional array into a DataFrame\n",
    "edge_df = pd.DataFrame(A_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff6cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df.rename(columns={0: 'source', 1: 'target', 2: 'loss_co'},inplace=True)\n",
    "node_df.rename(columns={0: 'Junction_in', 1: 'demand', 2: 'Measurement_in',3:'measurement',4:'head'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b47c4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "node_train, node_test = train_test_split(node_df,test_size=0.2,random_state=42)\n",
    "edge_train = edge_df.loc[~((edge_df['source'].isin(node_test.index)) | (edge_df['target'].isin(node_test.index)))]\n",
    "edge_test = edge_df.loc[(edge_df['source'].isin(node_test.index)) | (edge_df['target'].isin(node_test.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8448eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_tensor(node_df, edge_df):\n",
    "    graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "        node_sets={\n",
    "            \"node\": tfgnn.NodeSet.from_fields(\n",
    "                sizes=[len(node_df)],\n",
    "                features={\n",
    "                    'Junction_in':np.array(node_df['Junction_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'demand': np.array(node_df['demand'], dtype='float32').reshape(len(node_df),1),\n",
    "                    'Measurement_in': np.array(node_df['Measurement_in'], dtype='int32').reshape(len(node_df),1),\n",
    "                    'measurement': np.array(node_df['measurement'], dtype='float32').reshape(len(node_df),1),\n",
    "                    'head':np.array(node_df['head'], dtype='float32').reshape(len(node_df),1),\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        edge_sets={\n",
    "            \"link\": tfgnn.EdgeSet.from_fields(\n",
    "                sizes=[len(edge_df)],\n",
    "                features={\n",
    "                    'loss_co': np.array(edge_df['loss_co'], dtype='float32').reshape(len(edge_df),1),\n",
    "                },\n",
    "                adjacency=tfgnn.Adjacency.from_indices(\n",
    "                                          source=(\"node\", np.array(edge_df['source'], dtype='int32')),\n",
    "                                          target=(\"node\", np.array(edge_df['target'], dtype='int32')),\n",
    "                                      ))\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return graph_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a236f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tensor = create_graph_tensor(node_df, edge_df)\n",
    "train_tensor = create_graph_tensor(node_train, edge_train)\n",
    "test_tensor = create_graph_tensor(node_test, edge_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1813e735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensor(\n",
       "  context=Context(features={}, sizes=[1], shape=(), indices_dtype=tf.int32),\n",
       "  node_set_names=['node'],\n",
       "  edge_set_names=['link'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d9c8d",
   "metadata": {},
   "source": [
    "split off ‘head’ as our target (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a08b1bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_batch_merge(graph):\n",
    "    graph = graph.merge_batch_to_components()\n",
    "    node_features = graph.node_sets['node'].get_features_dict()\n",
    "    edge_features = graph.edge_sets['link'].get_features_dict()\n",
    "\n",
    "    label = node_features.pop('head')\n",
    "    print(label)\n",
    "\n",
    "    new_graph = graph.replace_features(node_sets={'node': node_features}, edge_sets={'link': edge_features})\n",
    "    return new_graph, label\n",
    "\n",
    "\n",
    "def create_dataset(graph, function):\n",
    "    dataset = tf.data.Dataset.from_tensors(graph)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset.map(function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a1395",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d9e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_node_dataset = create_dataset(train_tensor, node_batch_merge)\n",
    "test_node_dataset = create_dataset(test_tensor, node_batch_merge)\n",
    "full_node_dataset = create_dataset(full_tensor, node_batch_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d116b20",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a798ce8",
   "metadata": {},
   "source": [
    "## Build model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "498566f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_spec = train_node_dataset.element_spec[0]\n",
    "input_graph = tf.keras.layers.Input(type_spec=graph_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3493ee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n"
     ]
    }
   ],
   "source": [
    "def set_initial_node_state(node_set, node_set_name):\n",
    "    features = [\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Junction_in']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['demand']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['Measurement_in']),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(node_set['measurement']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n",
    "def set_initial_edge_state(edge_set, edge_set_name):\n",
    "    features = [\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\")(edge_set['loss_co']),\n",
    "    ]\n",
    "    return tf.keras.layers.Concatenate()(features)\n",
    "\n",
    "\n",
    "graph = tfgnn.keras.layers.MapFeatures(node_sets_fn=set_initial_node_state,\n",
    "                                       edge_sets_fn=set_initial_edge_state)(input_graph)\n",
    "\n",
    "\n",
    "def dense_layer(units=32, l2_reg=0.1, dropout=0.25, activation='relu'):\n",
    "    regularizer = tf.keras.regularizers.l2(l2_reg)\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units, kernel_regularizer=regularizer, bias_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(dropout)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8aa450",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1e02fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [()]                      0         \n",
      "                                                                 \n",
      " map_features (MapFeatures)  ()                        320       \n",
      "                                                                 \n",
      " graph_update (GraphUpdate)  ()                        19552     \n",
      "                                                                 \n",
      " graph_update_1 (GraphUpdate  ()                       11360     \n",
      " )                                                               \n",
      "                                                                 \n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      " input.node_sets (InstancePr  {'node': ()}             0         \n",
      " operty)                                                         \n",
      "                                                                 \n",
      " input._get_features_ref_5 (  {'hidden_state': (None,   0        \n",
      " InstanceProperty)           64)}                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,297\n",
      "Trainable params: 31,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "graph_updates = 2\n",
    "for i in range(graph_updates):\n",
    "    graph = tfgnn.keras.layers.GraphUpdate(\n",
    "        node_sets={\n",
    "            'node':\n",
    "            tfgnn.keras.layers.NodeSetUpdate(\n",
    "                {\n",
    "                    'link':\n",
    "                    tfgnn.keras.layers.SimpleConv(message_fn=dense_layer(32),\n",
    "                                                  reduce_type=\"sum\",\n",
    "                                                  sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
    "                                                  receiver_tag=tfgnn.TARGET)\n",
    "                }, tfgnn.keras.layers.NextStateFromConcat(dense_layer(64)))\n",
    "        })(graph)\n",
    "\n",
    "\n",
    "logits = tf.keras.layers.Dense(1)(graph.node_sets[\"node\"][tfgnn.HIDDEN_STATE])\n",
    "\n",
    "node_model = tf.keras.Model(input_graph, logits)\n",
    "node_model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                   loss='mean_squared_error',\n",
    "                   metrics=['mean_squared_error'])\n",
    "node_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d63e7b",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a074ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 2s 76ms/step - loss: 7810353664.0000 - mean_squared_error: 7810353664.0000 - val_loss: 469206784.0000 - val_mean_squared_error: 469206784.0000\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 2083572864.0000 - mean_squared_error: 2083572864.0000 - val_loss: 1038971328.0000 - val_mean_squared_error: 1038971328.0000\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 838636224.0000 - mean_squared_error: 838636224.0000 - val_loss: 148192592.0000 - val_mean_squared_error: 148192576.0000\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 326144352.0000 - mean_squared_error: 326144352.0000 - val_loss: 151231616.0000 - val_mean_squared_error: 151231600.0000\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 207326544.0000 - mean_squared_error: 207326512.0000 - val_loss: 29029060.0000 - val_mean_squared_error: 29029038.0000\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 50903184.0000 - mean_squared_error: 50903164.0000 - val_loss: 3060626.0000 - val_mean_squared_error: 3060602.0000\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 37253608.0000 - mean_squared_error: 37253584.0000 - val_loss: 10441227.0000 - val_mean_squared_error: 10441203.0000\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 18303052.0000 - mean_squared_error: 18303028.0000 - val_loss: 4989142.5000 - val_mean_squared_error: 4989118.5000\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 21110842.0000 - mean_squared_error: 21110820.0000 - val_loss: 4191021.0000 - val_mean_squared_error: 4190996.7500\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 11386276.0000 - mean_squared_error: 11386253.0000 - val_loss: 2067839.7500 - val_mean_squared_error: 2067815.1250\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 7925638.0000 - mean_squared_error: 7925613.5000 - val_loss: 1653047.2500 - val_mean_squared_error: 1653022.3750\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 7273105.0000 - mean_squared_error: 7273079.5000 - val_loss: 1250663.3750 - val_mean_squared_error: 1250638.2500\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 4399113.0000 - mean_squared_error: 4399088.0000 - val_loss: 1147567.6250 - val_mean_squared_error: 1147542.2500\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 4778864.0000 - mean_squared_error: 4778838.0000 - val_loss: 912587.8750 - val_mean_squared_error: 912562.0625\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 5342117.0000 - mean_squared_error: 5342091.5000 - val_loss: 762517.7500 - val_mean_squared_error: 762491.5625\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 3868780.5000 - mean_squared_error: 3868754.0000 - val_loss: 738768.1250 - val_mean_squared_error: 738741.5000\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 4100354.2500 - mean_squared_error: 4100327.2500 - val_loss: 506407.7812 - val_mean_squared_error: 506380.6562\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 2736973.0000 - mean_squared_error: 2736945.7500 - val_loss: 614484.1250 - val_mean_squared_error: 614456.4375\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 2186314.5000 - mean_squared_error: 2186286.7500 - val_loss: 690107.5625 - val_mean_squared_error: 690079.2500\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 1962284.6250 - mean_squared_error: 1962256.1250 - val_loss: 723144.6875 - val_mean_squared_error: 723115.6875\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 2537871.0000 - mean_squared_error: 2537841.7500 - val_loss: 808866.8125 - val_mean_squared_error: 808837.1250\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 2507516.5000 - mean_squared_error: 2507486.7500 - val_loss: 805341.9375 - val_mean_squared_error: 805311.4375\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 2069041.2500 - mean_squared_error: 2069010.5000 - val_loss: 626000.3125 - val_mean_squared_error: 625969.0000\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 2729565.2500 - mean_squared_error: 2729533.2500 - val_loss: 576486.1250 - val_mean_squared_error: 576453.9375\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 1972928.6250 - mean_squared_error: 1972896.0000 - val_loss: 538299.5000 - val_mean_squared_error: 538266.3750\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 1355291.7500 - mean_squared_error: 1355258.1250 - val_loss: 514853.9375 - val_mean_squared_error: 514819.8125\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 1583876.2500 - mean_squared_error: 1583841.6250 - val_loss: 454157.0938 - val_mean_squared_error: 454121.9375\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 1s 65ms/step - loss: 1897253.3750 - mean_squared_error: 1897217.7500 - val_loss: 426072.2188 - val_mean_squared_error: 426035.9375\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 1s 65ms/step - loss: 2063808.2500 - mean_squared_error: 2063771.5000 - val_loss: 509445.9688 - val_mean_squared_error: 509408.5938\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 2008322.0000 - mean_squared_error: 2008284.0000 - val_loss: 450063.6875 - val_mean_squared_error: 450025.0625\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1803621.5000 - mean_squared_error: 1803582.2500 - val_loss: 266579.3438 - val_mean_squared_error: 266539.4062\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 1030286.6875 - mean_squared_error: 1030246.1250 - val_loss: 331189.8438 - val_mean_squared_error: 331148.5312\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 933764.0000 - mean_squared_error: 933722.0000 - val_loss: 282783.2812 - val_mean_squared_error: 282740.5625\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 1205114.1250 - mean_squared_error: 1205070.7500 - val_loss: 250689.2812 - val_mean_squared_error: 250645.0781\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 1457202.0000 - mean_squared_error: 1457157.1250 - val_loss: 222831.6875 - val_mean_squared_error: 222785.9531\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 1238198.7500 - mean_squared_error: 1238152.3750 - val_loss: 191939.2812 - val_mean_squared_error: 191891.9375\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 1321080.3750 - mean_squared_error: 1321032.1250 - val_loss: 212049.5625 - val_mean_squared_error: 212000.5625\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 933733.0625 - mean_squared_error: 933683.2500 - val_loss: 183957.6719 - val_mean_squared_error: 183906.9375\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 834478.7500 - mean_squared_error: 834427.1875 - val_loss: 164467.2812 - val_mean_squared_error: 164414.7500\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 677100.5625 - mean_squared_error: 677047.2500 - val_loss: 174649.4844 - val_mean_squared_error: 174595.0938\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 902554.7500 - mean_squared_error: 902499.5000 - val_loss: 176208.1719 - val_mean_squared_error: 176151.8594\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 986024.6250 - mean_squared_error: 985967.5000 - val_loss: 168381.6719 - val_mean_squared_error: 168323.3594\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 785936.1250 - mean_squared_error: 785876.8750 - val_loss: 150364.6094 - val_mean_squared_error: 150304.2500\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 978298.2500 - mean_squared_error: 978236.8125 - val_loss: 150949.0469 - val_mean_squared_error: 150886.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 718980.0000 - mean_squared_error: 718916.6250 - val_loss: 198923.5156 - val_mean_squared_error: 198858.8281\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 922770.9375 - mean_squared_error: 922705.1250 - val_loss: 170620.7500 - val_mean_squared_error: 170553.7969\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 844824.3125 - mean_squared_error: 844756.3750 - val_loss: 146816.4062 - val_mean_squared_error: 146747.1094\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 533327.5000 - mean_squared_error: 533257.1875 - val_loss: 139479.1562 - val_mean_squared_error: 139407.4688\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 503016.4062 - mean_squared_error: 502943.6875 - val_loss: 141122.1875 - val_mean_squared_error: 141048.0312\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 867345.6250 - mean_squared_error: 867270.3750 - val_loss: 156844.3281 - val_mean_squared_error: 156767.6406\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 745372.6875 - mean_squared_error: 745294.8750 - val_loss: 191798.1875 - val_mean_squared_error: 191718.8906\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 471288.4375 - mean_squared_error: 471207.9062 - val_loss: 213800.3750 - val_mean_squared_error: 213718.3906\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 586101.8125 - mean_squared_error: 586018.5625 - val_loss: 171005.4531 - val_mean_squared_error: 170920.7188\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 637015.1875 - mean_squared_error: 636929.3125 - val_loss: 140029.9531 - val_mean_squared_error: 139942.4062\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 652362.1875 - mean_squared_error: 652273.2500 - val_loss: 128555.2500 - val_mean_squared_error: 128464.8047\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 440900.3125 - mean_squared_error: 440808.5000 - val_loss: 129843.9844 - val_mean_squared_error: 129750.5703\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 356183.7812 - mean_squared_error: 356089.0000 - val_loss: 138716.0000 - val_mean_squared_error: 138619.5469\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 412720.2500 - mean_squared_error: 412622.4375 - val_loss: 136927.8438 - val_mean_squared_error: 136828.2969\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 564040.4375 - mean_squared_error: 563939.4375 - val_loss: 129478.1719 - val_mean_squared_error: 129375.4609\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 376966.4062 - mean_squared_error: 376862.1875 - val_loss: 130293.2656 - val_mean_squared_error: 130187.2969\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 452996.4688 - mean_squared_error: 452888.9688 - val_loss: 131338.3438 - val_mean_squared_error: 131229.0469\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 592019.4375 - mean_squared_error: 591908.6875 - val_loss: 138489.0625 - val_mean_squared_error: 138376.3594\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 425322.1562 - mean_squared_error: 425207.9062 - val_loss: 140569.7656 - val_mean_squared_error: 140453.5938\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 560908.1250 - mean_squared_error: 560790.3125 - val_loss: 133985.6406 - val_mean_squared_error: 133865.9375\n",
      "Epoch 65/1000\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 432172.0938 - mean_squared_error: 432051.0312Restoring model weights from the end of the best epoch: 55.\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 427255.1250 - mean_squared_error: 427133.8438 - val_loss: 138079.0469 - val_mean_squared_error: 137955.7812\n",
      "Epoch 65: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e4b6533190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "\n",
    "node_model.fit(train_node_dataset.repeat(),\n",
    "               validation_data=test_node_dataset,\n",
    "               steps_per_epoch=10,\n",
    "               epochs=1000,\n",
    "               callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a36fc",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c51dc1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step - loss: 128555.2500 - mean_squared_error: 128464.8047\n",
      "{'loss': 128555.25, 'mean_squared_error': 128464.8046875}\n"
     ]
    }
   ],
   "source": [
    "eval_result = node_model.evaluate(test_node_dataset)\n",
    "print(dict(zip(node_model.metrics_names, eval_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11677aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
